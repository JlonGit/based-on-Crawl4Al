{
  "https://docs.siliconflow.cn": "<h1>产品简介 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​产品介绍</h2>\n<h2>​产品功能</h2>\n<h2>​产品特性</h2>",
  "https://docs.siliconflow.cn/cn/faqs/stream-mode": "<h1>流式输出 - SiliconFlow</h1>\n<h5>常见问题</h5>\n<h2>​1. 在 python 中使用流式输出</h2>\n<h3>​1.1 基于 openai 库的流式输出</h3>\n<p>在一般场景中，推荐您使用 openai 的库进行流式输出。</p>\n<h3>​1.2 基于 requests 库的流式输出</h3>\n<p>如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意：\n除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream = True, 才能正常按照 stream 模式进行返回。</p>",
  "https://docs.siliconflow.cn/cn/userguide/quickstart": "<h1>快速上手 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 登录平台</h2>\n<p>访问 SiliconCloud官网 并点击右上角“登录”按钮，按照提示填写您的基本信息进行登录。\n（目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录）</p>\n<h2>​2. 查看模型列表和模型详情</h2>\n<p>通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的“在线体验”进入到模型体验中心。</p>\n<h2>​3. 在 playground 体验 GenAI 能力</h2>\n<p>进入“体验中心( playground )”页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击“运行”按钮，即可看到模型生成的结果。</p>\n<h2>​4. 使用 SiliconCloud API 调用GenAI 能力</h2>\n<h3>​4.1 通过REST 接口进行服务调用</h3>\n<p>您可以直接在平台的“文档链接”中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。</p>\n<h3>​4.2 通过 OpenAI 接口调用</h3>\n<p>当前大语言模型部分支持以 openai 库进行调用，\n安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端/命令行运行：</p>\n<p>完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。\n之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。</p>",
  "https://docs.siliconflow.cn/cn/userguide/guides/fim": "<h1>FIM 补全 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。</p>\n<h2>​2. 使用方式</h2>\n<h3>​2.1 在 chat/completions 接口中使用</h3>\n<h3>​2.2 在 completions 接口中使用</h3>\n<h2>​3. 支持模型列表</h2>\n<p>Deepseek 系列：</p>\n<p>Qwen系列：</p>\n<h2>​4. 使用示例</h2>\n<h3>​4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：</h3>\n<h3>​4.2 基于 OpenAI 的 completions 接口使用 FIM 补全：</h3>",
  "https://docs.siliconflow.cn/cn/release-notes/overview": "<h1>更新公告 - SiliconFlow</h1>\n<h5>产品公告</h5>\n<h3>平台服务调整通知</h3>\n<h4>1. 模型下线通知</h4>\n<p>为了提供更稳定、高质量、可持续的服务，以下模型将于 2025 年 02 月 27 日下线：</p>\n<p>如果您有使用上述模型，建议尽快迁移至平台上的其他模型。</p>\n<h3>平台服务调整通知</h3>\n<h4>deepseek-ai/DeepSeek-V3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价</h4>\n<p>具体价格：</p>\n<h3>推理模型输出调整通知</h3>\n<p>推理模型思维链的展示方式，从之前的 content 中的 <think></think> 独立成单独的单独的 reasoning_content 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeek-R1）使用。</p>\n<h3>平台服务调整通知</h3>\n<h4>支持deepseek-ai/DeepSeek-R1和deepseek-ai/DeepSeek-V3模型</h4>\n<p>具体价格如下：</p>\n<h3>平台服务调整通知</h3>\n<h4>生成图片及视频 URL 有效期调整为 1 小时</h4>\n<p>为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。</p>\n<p>若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。</p>\n<h3>平台服务调整通知</h3>\n<h4>LTX-Video 模型即将开始计费通知</h4>\n<p>为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 Lightricks/LTX-Video 模型的视频生成请求进行计费，价格为 0.14 元 / 视频。</p>\n<h3>平台服务调整通知</h3>\n<h4>1.新增全局接入 API 端点</h4>\n<p>新增全局接入API端点：https://api.siliconflow.com。如果您在使用源端点 https://api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。</p>\n<h3>平台服务调整通知</h3>\n<h4>1. 模型下线通知</h4>\n<p>为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线：</p>\n<p>如果您有使用上述模型，建议尽快迁移至平台上的其他模型。</p>\n<h3>平台服务调整通知</h3>\n<h4>1. 模型下线通知</h4>\n<p>为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线：</p>\n<p>如果您有使用上述模型，建议尽快迁移至平台上的其他模型。</p>\n<p>如果您有使用上述模型，建议尽快迁移至平台上的其他模型。</p>\n<h3>平台服务调整通知</h3>\n<h4>1. 模型下线通知</h4>\n<p>为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线：</p>\n<p>如果您有使用上述模型，建议尽快迁移至平台上的其他模型。</p>\n<h4>2.邮箱登录方式更新</h4>\n<p>为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的“邮箱账户 + 密码”方式更新为“邮箱账户 + 验证码”方式。</p>\n<h4>3. 新增海外 API 端点</h4>\n<p>新增支持海外用户的平台端点：https://api-st.siliconflow.cn。如果您在使用源端点 https://api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。</p>\n<h3>部分模型计价调整公告</h3>\n<p>为了提供更加稳定、优质、可持续的服务，Vendor-A/Qwen/Qwen2-72B-Instruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下：</p>",
  "https://docs.siliconflow.cn/cn/legals/terms-of-service": "<h1>用户协议 - SiliconFlow</h1>\n<h5>法务条款</h5>\n<p>这是您与北京硅基流动科技有限公司及其关联方（“硅基流动”或“我们”）之间的协议（“本协议”），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择“同意”并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见《隐私政策》。</p>\n<h2>​1. 账户管理</h2>\n<p>1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人；本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。</p>\n<p>1.2 账户\n1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。\n1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。\n1.2.3 如果您通过第三方连接/访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。\n1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。</p>\n<p>1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。</p>\n<p>1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。</p>\n<p>1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。</p>\n<h2>​2. 访问服务及服务限制</h2>\n<p>2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。</p>\n<p>2.2 服务限制 \n2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译；\n2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术；\n2.2.3 未经我们事先书面同意，购买、出售或转让API密钥；\n2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文）；\n2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为；\n2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的;(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的；(iii)损害国家荣誉和利益的;(iv)煽动地域歧视、地域仇恨的；(v)煽动民族仇恨、民族歧视，破坏民族团结的；(vi)破坏国家宗教政策，宣扬邪教和封建迷信的；(vii)散布谣言，扰乱社会秩序，破坏社会稳定的；(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的；(ix)侮辱或者诽谤他人，侵害他人合法权益的；(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的；(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的；(xiii)有可能侵犯他人在先权利的；(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的；(xv)涉及他人隐私、个人信息或资料的；(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的；(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的；(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的“七条底线”要求的；(xx)相关法律、行政法规等禁止的。\n2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能；\n2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输；\n2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件；\n2.2.10 通过本服务传输违法数据、病毒或其他软件代理；\n2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务；或从本服务收集或获取包括用户姓名在内的任何个人信息。\n2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。\n2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。</p>\n<h2>​3. 用户内容</h2>\n<p>3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（“用户内容”）。详细数据使用政策请见本平台的《隐私政策》。</p>\n<p>3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。</p>\n<p>3.3 关于您的用户内容，您确认、声明并保证：\n3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任；\n3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利；\n3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权；\n3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利；\n3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息；\n3.3.6 您的用户内容不包括裸体或其他性暗示内容；不包括对个人或团体的仇恨言论、威胁或直接攻击；不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容；不包括性别歧视或种族、民族或其他歧视性内容；不包括含有自残或过度暴力的内容；不包括伪造或冒名顶替的档案；不包括非法内容或助长有害或非法活动的内容；不包括恶意程式或程式码；不包括未经本人同意的任何人的个人信息；不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容；\n3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。</p>\n<p>3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。</p>\n<p>3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。</p>\n<p>3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。</p>\n<h2>​4. 知识产权</h2>\n<p>4.1 定义。就本协议而言，“知识产权”系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。</p>\n<p>4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。</p>\n<p>4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）；（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）；（iii）您不得表示大模型的输出结果是人为生成的；（iv）您不得违反任何模型提供商的授权许可或使用限制。\n您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。</p>\n<p>4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（“用户使用数据”）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务；（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的《隐私政策》。</p>\n<p>4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（“反馈”），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。</p>\n<h2>​5. 保密信息</h2>\n<p>本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（“保密信息”）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度；（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的；以及（c）不向任何个人或实体披露任何保密信息。</p>\n<h2>​6. 计费政策及税费</h2>\n<p>您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（“费用”）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价/付款条件/充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和/或服务的额外费用、增加或修改现有产品和/或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和/或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用/开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contact@siliconflow.cn联系我们。</p>\n<h2>​7. 隐私与数据安全</h2>\n<p>7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（“用户信息”），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守《中华人民共和国个人信息保护法》及相关适用法律。</p>\n<p>7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。</p>\n<h2>​8. 使用第三方服务</h2>\n<p>本服务可能包含非我们拥有或控制的第三方网站、资料和服务（“第三方服务”）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。</p>\n<h2>​9. 赔偿</h2>\n<p>您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（“硅基流动受偿方”）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用；（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证；（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权；（d）您违反任何适用法律；（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息；（f）您故意的或者存在重大过失的不当行为；或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。</p>\n<h2>​10. 免责声明</h2>\n<p>您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。\n通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。</p>\n<h2>​11. 责任限制和免责</h2>\n<p>硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害；或者（b）数据丢失或受损，或者业务中断或损失；或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。</p>\n<h2>​12. 适用法律及争议解决条款</h2>\n<p>本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。\n若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。</p>\n<h2>​13. 其他条款</h2>\n<p>13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。</p>\n<p>13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。</p>\n<p>13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准；您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。</p>",
  "https://docs.siliconflow.cn/cn/userguide/guides/prefix": "<h1>前缀续写 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。\n基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。</p>\n<h2>​2. 使用方式</h2>\n<p>在请求中添加</p>\n<h2>​3. 支持模型列表</h2>\n<p>目前大语言类模型支持上述参数。</p>\n<h2>​4. 使用示例</h2>\n<p>下面是基于 OpenAI 库使用前缀续写的例子：</p>",
  "https://docs.siliconflow.cn/cn/userguide/guides/json-mode": "<h1>JSON 模式 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。</p>\n<p>作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。</p>\n<p>现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。</p>\n<p>比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出：</p>\n<h2>​2. 使用方式</h2>\n<p>在请求中添加</p>\n<h2>​3. 支持模型列表</h2>\n<p>目前线上提供的大语言类模型都支持上述参数。</p>\n<h2>​4. 使用示例</h2>\n<p>下面是在 openai 中使用的例子：</p>\n<p>模型将输出：</p>",
  "https://docs.siliconflow.cn/cn/userguide/guides/fine-tune": "<h1>模型微调 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 模型微调简介</h2>\n<p>模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处：</p>\n<p>SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调：</p>\n<p>生图模型已支持：</p>\n<p>对话模型已支持：</p>\n<p>最新支持的模型参考模型微调</p>\n<h2>​2. 使用流程</h2>\n<h3>​2.1 准备数据</h3>\n<h4>​2.2.1 生图模型数据准备</h4>\n<p>数据集要求如下：</p>\n<p>数据集本地文件夹示例如图:</p>\n<h4>​2.2.2 语言模型数据准备</h4>\n<p>仅支持 .jsonl 文件，且需符合以下要求：</p>\n<p>如下为数据示例：</p>\n<h3>​2.2 新建并配置微调任务</h3>\n<h3>​2.3 开始训练</h3>\n<h3>​2.4 调用微调模型</h3>\n<h4>​2.4.1 生图微调模型调用</h4>\n<p>示例如下：</p>\n<h4>​2.4.2 对话微调模型调用</h4>\n<p>下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子：</p>\n<h2>​3. 参数配置详解</h2>\n<p>对话模型</p>\n<h2>​4. 基于SiliconCloud微调服务来优化业务实战</h2>\n<p>之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成“金句”风格的描述语句。\n现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。</p>\n<h3>​4.1 在平台上使用“智说新语”的语料按照上述进行微调。</h3>\n<p>步骤见模型微调使用流程\n详细语料和测试代码见siliconcloud-cookbook</p>\n<h3>​4.2 对比微调前后的效果</h3>\n<p>使用方式见模型微调调用模型</p>\n<h4>​4.2.1 模型输入</h4>\n<p>微调前：\nQwen2.5-7B-Instruct 系统Prompt:</p>\n<p>Qwen2.5-7B-Instruct+智说新语微调后的Prompt:</p>\n<h4>​4.2.2 模型输出</h4>\n<h4>​4.2.3 微调总结</h4>",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/video": "<h1>视频生成模型 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域：</p>\n<h2>​2. 使用建议</h2>\n<p>在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。</p>\n<p>为了获得最佳效果，请按照以下结构构建提示词：</p>\n<p>上述prompt生成的视频示例：</p>\n<p>Your browser does not support the video tag.</p>\n<h2>​3. 体验地址</h2>\n<p>可以点击playground进行体验</p>\n<h2>​4. 支持模型</h2>\n<h3>​4.1 文生视频模型</h3>\n<p>目前已经支持的文生视频模型：</p>\n<p>Lightricks/LTX-Video</p>\n<p>该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。</p>\n<p>tencent/HunyuanVideo</p>\n<p>该模型价格0.7元/Video，支持API调用。</p>\n<p>genmo/mochi-1-preview</p>\n<p>该模型价格2.8元/Video，支持API调用。</p>\n<h3>​4.2 图生视频模型</h3>\n<p>Lightricks/LTX-Video</p>\n<p>该模型进行图生视频调用时候，价格0.14元/Video，当前仅支持API调用。</p>",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/vision": "<h1>视觉语言模型 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如：</p>\n<h2>​2. 使用方式</h2>\n<p>对于 VLM 模型，可在调用 /chat/completions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。</p>\n<h3>​2.1 关于图片细节控制参数说明</h3>\n<p>SiliconCloud 提供 low，high，auto 三个 detail 参数选项。\n对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（“高分辨率”）模式，而指定为 low 或者 auto 时会采用 low（“低分辨率”）模式。</p>\n<h3>​2.2 包含图像的 message 消息格式示例</h3>\n<h4>​使用图片 url 形式</h4>\n<h4>​2.2 base64 形式</h4>\n<h4>​2.3 多图片形式，其中每个图片可以是上述两种形式之一</h4>\n<h2>​3. 支持模型列表</h2>\n<p>目前已支持的 VLM 模型：</p>\n<h2>​4. 视觉输入内容计费方式</h2>\n<p>对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。</p>\n<h3>​4.1 Qwen 系列</h3>\n<p>规则：</p>\n<p>Qwen 最高支持像素是 3584 * 3584= 12845056，最低支持像素是 56 * 56 = 3136，会对先对每张图片长短边均放缩至28的倍数 (h * 28) * (w * 28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。</p>\n<p>示例：</p>\n<h3>​4.2 InternVL 系列</h3>\n<p>规则：</p>\n<p>InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448 * 448，最高为 12 * 448 * 448。</p>\n<p>示例:</p>\n<h3>​4.3 DeepseekVL2系列</h3>\n<p>规则：</p>\n<p>DeepseekVL2对于每张图片，会处理global_view和local_view两部分。global_view将原图片统一resize成384*384像素大小，local_view会将每张图片划分成若干384*384的块大小。图片中间会根据宽度增加额外token来衔接。</p>\n<p>放缩的长宽h * w按照如下规则选择：</p>\n<p>token消耗按照如下规则:</p>\n<p>示例:</p>\n<h2>​5. 使用示例</h2>\n<h3>​5.1. 示例 1 图片理解</h3>\n<h3>​5.2. 示例 2 多图理解</h3>",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/images": "<h1>生图模型 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1.生图模型简介</h2>\n<p>平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像；一种是根据现有图像，加上prompt输入，生成图像变体。</p>\n<p>根据文本提示创建图像</p>\n<p>在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧：</p>\n<p>具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入“海滩日落”，而是可以尝试输入“一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船”。</p>\n<p>情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如“温馨的”、“神秘的”、“充满活力的”等，这样可以帮助模型更好地理解你想要的风格。</p>\n<p>风格指定：如果你有特定的艺术风格偏好，比如“印象派”、“超现实主义”等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。</p>\n<p>避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如“美”、“好”等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。</p>\n<p>使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，“生成一幅海滩日落的图片，但不要有船”。</p>\n<p>分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。</p>\n<p>尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。</p>\n<p>利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。</p>\n<p>通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。</p>\n<p>可以参考如下示例：</p>\n<p>A futuristic eco-friendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structure’s design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern eco-architecture with traditional city landmarks.</p>\n<p>An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animal’s fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopard’s habitat, with mist and mountain peaks fading into the background.</p>\n<p>有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。</p>\n<h2>​2.体验地址</h2>\n<p>可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。</p>\n<p>重点参数介绍</p>\n<p>image_size：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。</p>\n<p>num_inference_steps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型black-forest-labs/FLUX.1-schnell、Pro/black-forest-labs/FLUX.1-schnell和stabilityai/stable-diffusion-3-5-large-turbo不支持调整步长，默认的步长是4。</p>\n<p>prompt_enhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。</p>\n<p>batch_size：一次生成图像的个数，默认值是1，最大值可以设置为4</p>\n<p>negative_prompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。</p>\n<p>seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。</p>\n<h2>​3.生图计费介绍</h2>\n<p>平台的生图计费分为两种计费方式：</p>\n<p>根据图像大小及图像步长进行计费，单价是 ¥x/M px/Steps，即每M像素每步长是x元。</p>\n<p>比如想要生成一个宽1024*高512、4步长的图像，选择单价是¥0.0032/M px/Steps的stabilityai/stable-diffusion-3-5-large-turbo模型，那么生成一张图片的价格就是(1024x512)/(1024x1024)x4x0.0032=0.0064元，其中2代表宽1024*高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。</p>\n<p>根据图片张数进行计费，单价是¥x/Image，即每张图片的价格是x元。</p>\n<p>比如想要生成一个宽1024*高512像素，4步长的图像，选择单价是¥0.37/Image的black-forest-labs/FLUX.1-pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。</p>\n<h2>​4.支持模型列表</h2>\n<p>目前已支持的生图模型：</p>\n<p>black-forest-labs系列：</p>\n<p>stabilityai系列：</p>\n<p>deepseekai系列：</p>",
  "https://docs.siliconflow.cn/cn/userguide/use-docs-with-cursor": "<h1>结合 Cursor 使用 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<p>SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。\n考虑到部分用户可能对  llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。</p>\n<h2>​1. 在 Cursor 中使用本文档</h2>\n<h3>​1.1 配置本文档</h3>\n<p>配置 Cursor 的 @Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。</p>\n<h3>​1.2 在 cursor 中使用</h3>\n<h2>​2. 关于 llmx.txt 的相关介绍</h2>\n<h3>​2.1 协议背景</h3>\n<p>llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。</p>\n<h3>​2.2 文件结构：</h3>\n<p>llms.txt 文件采用 Markdown 格式，通常包含以下部分：</p>\n<p>示例如下（参考：https://docs.siliconflow.cn/llms.txt 和 https://docs.siliconflow.cn/llms-full.txt 文件)</p>\n<h3>​2.3 文件作用</h3>\n<h4>​2.3.1 /llms.txt：</h4>\n<h4>​2.3.2 /llms-full.txt：</h4>\n<h3>​2.4 与现有标准的区别：</h3>\n<p>虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同：</p>\n<h2>​3. 在其他工具中使用</h2>\n<p>其他平台如果支持llms.txt 协议，也可以直接使用。\n比如在 ChatGPT 中使用：</p>\n<h2>​4. 扩展阅读</h2>",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/reasoning": "<h1>推理模型 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​概述</h2>\n<p>DeepSeek-R1 是一系列由 deepseek-ai 开发的高级语言模型，旨在通过输出思维链内容（reasoning_content）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。</p>\n<h3>​支持模型列表：</h3>\n<h2>​安装与升级</h2>\n<p>在使用 DeepSeek-R1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级：</p>\n<h2>​API 参数</h2>\n<p>输入参数：\nmax_tokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseek-ai/DeepSeek-R11和Pro/deepseek-ai/DeepSeek-R1 max_tokens 最大为8K，其他模型 max_tokens 最大为16k。</p>\n<p>返回参数：</p>\n<p>reasoning_content：思维链内容，与 content 同级。</p>\n<p>content：最终回答内容</p>\n<h2>​上下文拼接</h2>\n<p>在每一轮对话过程中，模型会输出思维链内容（reasoning_content）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。</p>\n<h2>​openai请求示例</h2>\n<h3>​流式输出请求</h3>\n<h3>​非流式输出请求</h3>\n<h2>​注意事项</h2>\n<h2>​常见问题</h2>\n<p>如何获取 API 密钥？</p>\n<p>请访问 SiliconFlow 注册并获取 API 密钥。</p>\n<p>如何处理超长文本？</p>\n<p>可以通过调整 max_tokens 参数来控制输出的长度，但请注意最大长度为 16K。</p>",
  "https://docs.siliconflow.cn/cn/usercases/use-siliconcloud-in-bob": "<h1>在 Bob 翻译中使用 - SiliconFlow</h1>\n<h5>场景示例</h5>\n<h2>​1. 关于 Bob</h2>\n<p>Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！</p>\n<p>本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。</p>\n<h2>​2. 安装 Bob</h2>\n<p>前往 Mac App Store 安装 Bob。Mac App Store 安装</p>\n<h2>​3. 在 Bob 中使用 SiliconCloud</h2>\n<h3>​3.1 默认配置</h3>\n<p>安装完 Bob 之后，在任意软件选中一段文本，然后按下 ⌥ D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。</p>\n<h3>​3.2 使用 SiliconCloud 的其他免费模型</h3>\n<p>默认使用的模型是 Qwen/Qwen2.5-7B-Instruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往「翻译-服务」页面切换其他免费模型。</p>\n<p>如下图所示，标注为免费的模型均可直接使用。</p>\n<h3>​3.3 使用 SiliconCloud 的其他文本生成模型</h3>\n<p>如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。</p>",
  "https://docs.siliconflow.cn/cn/userguide/guides/function-calling": "<h1>Function Calling - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>Function Calling 功能让模型能够调用外部工具，来增强自身能力。\n该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。</p>\n<h2>​2. 使用方式</h2>\n<h3>​2.1 通过 REST API 添加 tools 请求参数</h3>\n<p>在请求体中添加</p>\n<p>比如完整的 payload 信息：</p>\n<h3>​2.2 通过 OpenAI 库请求</h3>\n<p>该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools=[对应的 tools]\n比如：</p>\n<h2>​3. 支持模型列表</h2>\n<p>目前支持的模型列表有：</p>\n<p>Deepseek 系列：</p>\n<p>书生系列：</p>\n<p>Qwen系列：</p>\n<p>GLM 系列：</p>\n<h2>​4. 使用示例</h2>\n<h3>​4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力</h3>\n<p>本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数\n来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。</p>\n<p>模型将输出：</p>\n<h3>​4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解</h3>\n<p>本代码输入 1 个函数，通过外部 API 来查询外部信息</p>\n<p>模型将输出：</p>",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/text-to-speech": "<h1>文本转语音模型 - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. 使用场景</h2>\n<p>文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景：</p>\n<h2>​2. API 使用指南</h2>\n<h3>​2.1 系统预置音色：</h3>\n<p>目前系统预置了如下 8 种音色：</p>\n<p>男生音色：</p>\n<p>女生音色：</p>\n<p>在线试听上述音频。</p>\n<p>在请求中使用系统预置音色。\n在使用对应的系统预置音色时，需要在前面加上模型名称，比如：</p>\n<p>FunAudioLLM/CosyVoice2-0.5B:alex 表示 FunAudioLLM/CosyVoice2-0.5B 模型下的 alex 音色。</p>\n<p>fishaudio/fish-speech-1.5:anna 表示 fishaudio/fish-speech-1.5 模型下的 anna 音色。</p>\n<p>RVC-Boss/GPT-SoVITS:david 表示 RVC-Boss/GPT-SoVITS 模型下的 david 音色。</p>\n<h3>​2.2 用户预置音色：</h3>\n<p>为保证生成语音效果，建议用户上传音色为：时间8～10s左右，发音吐字清晰，没有杂音/背景音。</p>\n<h4>​2.2.1 通过 base64 编码格式上传用户预置音色</h4>\n<p>上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。</p>\n<p>在请求中使用用户预置音色。</p>\n<h4>​2.2.2 通过文件上传用户预置音色</h4>\n<p>上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。</p>\n<p>在请求中使用用户预置音色。</p>\n<h3>​2.3 获取用户动态音色列表</h3>\n<p>上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。</p>\n<p>在请求中使用用户预置音色。</p>\n<h3>​2.4 使用用户动态音色</h3>\n<p>在请求中使用用户动态音色。</p>\n<h3>​2.5 删除用户动态音色</h3>\n<p>上述接口请求参数中的 uri 字段，即为自定义音色的 ID。</p>\n<h2>​3. 支持模型列表</h2>\n<h3>​3.1 fishaudio/fish-speech 系列模型</h3>\n<h3>​3.2 RVC-Boss/GPT-SoVITS 系列模型</h3>\n<h3>​3.3 FunAudioLLM/CosyVoice2-0.5B 系列模型</h3>\n<h2>​4. 参考音频的最佳实践</h2>\n<p>提供参考音频的高质量样本可以提升语音克隆效果。</p>\n<h3>​4.1 音频质量指南</h3>\n<h3>​4.2 文件格式</h3>\n<h2>​5. 使用示例</h2>\n<h3>​5.1 使用系统预置音色</h3>\n<h4>​5.2 使用用户预置音色</h4>\n<h4>​5.3 使用用户动态音色</h4>",
  "https://docs.siliconflow.cn/cn/api-reference/chat-completions/chat-completions": "<h1>创建文本对话请求 - SiliconFlow</h1>\n<h5>文本系列</h5>\n<h5>图像系列</h5>\n<h5>语音系列</h5>\n<h5>视频系列</h5>\n<h5>平台系列</h5>\n<h4>Authorizations</h4>\n<p>Use the following format for authentication: Bearer <your api key></p>\n<h4>Body</h4>\n<p>A list of messages comprising the conversation so far.</p>\n<p>The contents of the message.</p>\n<p>The role of the messages author. Choice between: system, user, or assistant.</p>\n<p>对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。</p>\n<p>The maximum number of tokens to generate.</p>\n<p>Number of generations to return</p>\n<p>An object specifying the format that the model must output.</p>\n<p>The type of the response format.</p>\n<p>Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.</p>\n<p>If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with data: [DONE]</p>\n<p>Determines the degree of randomness in the response.</p>\n<p>A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.</p>\n<p>The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.</p>\n<p>A description of what the function does, used by the model to choose when and how to call the function.</p>\n<p>The parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format.</p>\n<p>Omitting parameters defines a function with an empty parameter list.</p>\n<p>Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.</p>\n<p>The type of the tool. Currently, only function is supported.</p>\n<p>The top_p (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.</p>\n<h4>Response</h4>\n<p>仅deepseek-R1系列推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoning_content）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。</p>\n<p>The tool calls generated by the model, such as function calls.</p>\n<p>The function that the model called.</p>\n<p>The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.</p>\n<p>The name of the function to call.</p>\n<p>The ID of the tool call.</p>\n<p>The type of the tool. Currently, only function is supported.</p>",
  "https://docs.siliconflow.cn/cn/userguide/rate-limits/rate-limit-and-upgradation": "<h1>Rate Limits - SiliconFlow</h1>\n<h5>开始使用</h5>\n<h5>平台能力</h5>\n<h5>功能特性</h5>\n<h5>Rate Limits</h5>\n<h5>硅基流动产品集</h5>\n<h2>​1. Rate Limits 概述</h2>\n<h3>​1.1 什么是 Rate Limits</h3>\n<p>Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。</p>\n<h3>​1.2 为什么做 Rate Limits</h3>\n<p>Rate Limits 是 API 的常见做法，其实施原因如下：</p>\n<h3>​1.3 Rate Limits 指标</h3>\n<p>目前Rate Limit以六种指标衡量：</p>\n<h3>​1.4 不同模型的 Rate Limits 指标</h3>\n<p>Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。\n例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。</p>\n<h3>​1.5 Rate Limits 主体</h3>\n<h2>​2. Rate Limits 规则</h2>\n<h3>​2.1 免费模型Rate Limits</h3>\n<h3>​2.2 收费模型 Rate Limits</h3>\n<h3>​2.3 用户用量级别与 Rate Limits</h3>\n<p>平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的  Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的  Rate Limits。</p>\n<h3>​2.4 具体模型的 Rate Limits</h3>\n<p>平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的  Rate Limits 指标在模型广场中查看。</p>\n<h3>​2.5 部分模型是否实名的 Rate Limits</h3>\n<p>模型DeepSeek-R1 和 DeepSeek-V3 ，会根据是否实名对Rate Limits进行区分：</p>\n<p>未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 “Details: RPD limit reached. Could only send 100 requests per day without real name verification”，可以通过实名解锁更高的 Rate Limit。</p>\n<p>实名用户：拥有更高的 Rate Limit，具体值参考模型广场\n如果访问次数超过这些限制，也会收到 429 错误。</p>\n<h2>​3. 超出 Rate Limits 处理</h2>\n<h3>​3.1 超出 Rate Limits 报错信息</h3>\n<p>如果超出  Rate Limits 调用限制，用户的 API 请求将会因为超过  Rate Limits 而失败。用户需要等待一段时间待满足  Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为：</p>\n<h3>​3.2 超出 Rate Limits 处理方式</h3>\n<h2>​4. 如何提升模型 Rate Limits 指标</h2>\n<h3>​4.1 提升  Rate Limits 的方式</h3>\n<h3>​4.2 等级包购买细则</h3>\n<h3>​4.3 其他情况</h3>"
}