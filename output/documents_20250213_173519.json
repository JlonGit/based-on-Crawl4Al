{
  "https://docs.siliconflow.cn": "SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用产品简介用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用产品简介 SiliconFlow home page SiliconFlow home page SiliconFlow home page 开始使用产品简介 开始使用产品简介 开始使用 产品简介 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手在此页面产品介绍产品功能产品特性 产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。 快速上手 产品介绍 作为集合顶尖大模型的一站式云服务平台，SiliconCloud 致力于为开发者提供更快、更全面、体验更丝滑的模型 API，助力开发者和企业聚焦产品创新，无须担心产品大规模推广所带来的高昂算力成本。 产品功能 提供开箱即用的大模型 API，按量收费，助力应用开发轻松实现。 已上架包括 Qwen2.572B、DeepSeekV2.5、Qwen2、InternLM2.520BChat、BCE、BGE、SenseVoiceSmall、Llama3.1、FLUX.1、DeepSeekCoderV2、SD3 Medium、GLM49BChat、InstantID 在内的多种开源大语言模型、图片生成模型、代码生成模型、向量与重排序模型以及多模态大模型，覆盖语言、语音、图片、视频等多场景。 其中，Qwen2.5（7B）、Llama3.1（8B）等多个大模型 API 免费使用，让开发者与产品经理无需担心研发阶段和大规模推广所带来的算力成本，实现Token 自由。 25 年 1 月，SiliconCloud 平台上线基于华为云昇腾云服务的 DeepSeekV3、DeepSeekR1 推理服务。通过双方联合创新，在硅基流动自研推理加速引擎加持下，平台上的 DeepSeek 模型可获得持平全球高端 GPU 部署模型的效果。 提供高效能大模型推理加速服务，提升 GenAI 应用的用户体验。 提供模型微调与部署的托管服务，用户可直接托管经过微调的大语言模型，在支撑业务迭代的同时，无需关注底层资源、服务质量，有效降低维护成本。 产品特性 高速推理 自研高效算子和优化框架，推理加速引擎全球领先。 极致提升吞吐能力，全面支持高吞吐场景的业务需求。 显著优化计算延迟，为低延迟场景提供卓越性能保障。 高扩展性 动态扩容支持弹性业务模型，无缝适配多种复杂场景。 一键部署自定义模型，轻松应对规模化挑战。 灵活架构设计，满足多样化任务需求，支持混合云部署。 高性价比 端到端极致优化，推理和部署成本显著降低。 提供灵活按需付费模式，减少资源浪费，精准控制预算。 支持国产异构 GPU 部署，基于企业已有投资，节省企业投入。 高稳定性 经过开发者验证，保证高可靠稳定运行。 提供完善的监控和容错机制，保障服务能力。 提供专业技术支持，满足企业级场景需求，确保服务高可用性。 高智能 提供多种先进模型服务，包括大语言模型、音视频等多模态模型。 智能扩展功能，灵活适配业务规模，满足多种服务需求。 智能成本分析，为业务优化提供支持，助力成本管控与效益提升。 高安全性 支持 BYOC 部署，全面保护数据隐私与业务安全。 计算隔离网络隔离存储隔离，保障数据安全。 符合行业标准与合规要求，全面满足企业级用户的安全需求。    快速上手 快速上手 在此页面产品介绍产品功能产品特性 在此页面产品介绍产品功能产品特性 在此页面产品介绍产品功能产品特性 在此页面",
  "https://docs.siliconflow.cn/cn/faqs/stream-mode": "SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page常见问题流式输出用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page常见问题流式输出 SiliconFlow home page SiliconFlow home page SiliconFlow home page 常见问题流式输出 常见问题流式输出 常见问题 流式输出 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题 常见问题流式输出实名认证开具发票错误处理模型问题使用问题财务问题Rate Limits 问题 流式输出 流式输出 实名认证 实名认证 开具发票 开具发票 错误处理 错误处理 模型问题 模型问题 使用问题 使用问题 财务问题 财务问题 Rate Limits 问题 Rate Limits 问题 1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证 1. 在 python 中使用流式输出 1.1 基于 openai 库的流式输出 在一般场景中，推荐您使用 openai 的库进行流式输出。 from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 1.2 基于 requests 库的流式输出 如果您有非 openai 的场景，如您需要基于 request 库使用 siliconcloud API，请您注意： 除了 payload 中的 stream 需要设置外，request 请求的参数也需要设置stream  True, 才能正常按照 stream 模式进行返回。 import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode)   from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) from openai import OpenAI client  OpenAI( baseurlhttps:api.siliconflow.cnv1, apikeyyourapikey ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？ , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue)  import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) import requests url  https:api.siliconflow.cnv1chatcompletions payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: SiliconCloud公测上线，每用户送3亿token 解锁开源大模型创新能力。对于整个大模型应用领域带来哪些改变？  , stream: True  headers   accept: applicationjson, contenttype: applicationjson, authorization: Bearer yourapikey  response  requests.post(url, jsonpayload, headersheaders, streamTrue) if response.statuscode  200: for chunk in response.itercontent(chunksize8192): if chunk: decodedchunk  chunk.decode(utf8) print(decodedchunk, end) else: print(Request failed with status code:, response.statuscode) 实名认证 实名认证 在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 在此页面1. 在 python 中使用流式输出1.1 基于 openai 库的流式输出1.2 基于 requests 库的流式输出 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/quickstart": "SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用快速上手用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用快速上手 SiliconFlow home page SiliconFlow home page SiliconFlow home page 开始使用快速上手 开始使用快速上手 开始使用 快速上手 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用 1. 登录平台 访问 SiliconCloud官网 并点击右上角登录按钮，按照提示填写您的基本信息进行登录。 （目前平台支持短信登录、邮箱登录，以及 GitHub、Google 的 OAuth 登录） 2. 查看模型列表和模型详情 通过 模型广场 查看当前可用的模型详情、模型价格、用户可用的最高限速等信息，并可以通过模型详情页的在线体验进入到模型体验中心。 3. 在 playground 体验 GenAI 能力 进入体验中心( playground )页面，左侧栏可选择语言模型、文生图模型和图生图模型，选择相应模型即可开始实时体验。输入相关参数及 prompt ，点击运行按钮，即可看到模型生成的结果。 4. 使用 SiliconCloud API 调用GenAI 能力 4.1 通过REST 接口进行服务调用 您可以直接在平台的文档链接中使用您的 API key 进行在线调用，此处可以生成对应语言的代码。 4.2 通过 OpenAI 接口调用 当前大语言模型部分支持以 openai 库进行调用， 安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。从终端命令行运行： pip install upgrade openai 完成此操作后， running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。 from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end)       pip install upgrade openai pip install upgrade openai pip install upgrade openai from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) from openai import OpenAI client  OpenAI(apikeyYOURAPIKEY, baseurlhttps:api.siliconflow.cnv1) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战 , streamTrue ) for chunk in response: print(chunk.choices0.delta.content, end) 产品简介结合 Cursor 使用 产品简介结合 Cursor 使用 在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 在此页面1. 登录平台2. 查看模型列表和模型详情3. 在 playground 体验 GenAI 能力4. 使用 SiliconCloud API 调用GenAI 能力4.1 通过REST 接口进行服务调用4.2 通过 OpenAI 接口调用 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/guides/fim": "SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性FIM 补全用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性FIM 补全 SiliconFlow home page SiliconFlow home page SiliconFlow home page 功能特性FIM 补全 功能特性FIM 补全 功能特性 FIM 补全 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling 1. 使用场景 FIM (Fill In the Middle) 补全中，用户提供希望输入的前后内容，模型来补全中间的内容，典型用于代码补全、文本中间内容补全等场景中。 2. 使用方式 2.1 在 chatcompletions 接口中使用  model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容  2.2 在 completions 接口中使用  model: model info, prompt: 前缀内容, suffix: 后缀内容  3. 支持模型列表 Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 Qwen系列： QwenQwen2.5Coder7BInstruct QwenQwen2.5Coder32BInstruct 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end)     model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容   model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容   model: model info, messages: prompt message, params: params, extrabody: prefix:前缀内容, suffix:后缀内容    model: model info, prompt: 前缀内容, suffix: 后缀内容   model: model info, prompt: 前缀内容, suffix: 后缀内容   model: model info, prompt: 前缀内容, suffix: 后缀内容   注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。 注意：支持的模型列表可能会发生变化，请查阅本文档了解最新支持的模型列表。   client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabody prefix: f def quicksort(arr): if len(arr)  1: return arr else: , suffix: f arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr)  , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end)  client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.completions.create( modeldeepseekaiDeepSeekV2.5, promptf def quicksort(arr): if len(arr)  1: return arr else: , suffixf arr  3, 6, 8, 10, 1, 2, 1 sortedarr  quicksort(arr) print(Sorted array:, sortedarr) , streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.text, end) 前缀续写Function Calling 前缀续写Function Calling 在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 在此页面1. 使用场景2. 使用方式2.1 在 chatcompletions 接口中使用2.2 在 completions 接口中使用3. 支持模型列表4. 使用示例4.1 基于 OpenAI 的 chat.completions 接口使用FIM补全：4.2 基于 OpenAI 的 completions 接口使用 FIM 补全： 在此页面",
  "https://docs.siliconflow.cn/cn/release-notes/overview": "SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议产品公告更新公告2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议产品公告更新公告2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议产品公告更新公告2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page产品公告更新公告用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page产品公告更新公告 SiliconFlow home page SiliconFlow home page SiliconFlow home page 产品公告更新公告 产品公告更新公告 产品公告 更新公告 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 产品公告更新公告2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 产品公告更新公告 产品公告更新公告 产品公告更新公告 产品公告更新公告 产品公告更新公告 更新公告 更新公告 2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 2025.02.09平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.09  2025.02.09 平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 平台服务调整通知deepseekaiDeepSeekV3 模型的价格于北京时间 2025年2月9日00:00 起恢复至原价具体价格： 输入：2 M Tokens 输出：8 M Tokens 2025.02.03推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.03  2025.02.03 推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 推理模型输出调整通知推理模型思维链的展示方式，从之前的 content 中的 thinkthink 独立成单独的单独的 reasoningcontent 字段，兼容 openai 和 deepseek api 规范，便于各个框架和上层应用在进行多轮会话时进行裁剪。使用方式详见推理模型（DeepSeekR1）使用。 2025.02.01平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2025.02.01  2025.02.01 平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 平台服务调整通知支持deepseekaiDeepSeekR1和deepseekaiDeepSeekV3模型具体价格如下： deepseekaiDeepSeekR1 输入：4 M Tokens 输出：16 M Tokens deepseekaiDeepSeekV3 即日起至北京时间 20250208 24:00 享受限时折扣价：输入：21 M Tokens 输出：82 M Tokens，20250209 00:00恢复原价。 2024.12.27平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.27  2024.12.27 平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 平台服务调整通知生成图片及视频 URL 有效期调整为 1 小时为了持续为您提供更先进、优质的技术服务，从 2025 年 1 月 20 日起，大模型生成的图片、视频 URL 有效期将调整为 1 小时。若您正在使用图片、视频生成服务，请及时做好转存工作，避免因 URL 过期而影响业务。 2024.12.24平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.24  2024.12.24 平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 平台服务调整通知LTXVideo 模型即将开始计费通知为了持续为您提供更先进、优质的技术服务，平台将于 2025 年 1 月 6 日起对 LightricksLTXVideo 模型的视频生成请求进行计费，价格为 0.14 元  视频。 2024.12.18平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.18  2024.12.18 平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 平台服务调整通知1.新增全局接入 API 端点新增全局接入API端点：https:api.siliconflow.com。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.12.13平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.13  2024.12.13 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 19 日下线： deepseekaiDeepSeekV2Chat QwenQwen272BInstruct VendorAQwenQwen272BInstruct OpenGVLabInternVL2Llama376B 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.12.5  2024.12.5 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 12 月 13 日下线： QwenQwen2.5Math72BInstruct TencentHunyuanA52BInstruct nvidiaLlama3.1Nemotron70BInstruct 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。如果您有使用上述模型，建议尽快迁移至平台上的其他模型。 2024.11.14平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.11.14  2024.11.14 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 平台服务调整通知1. 模型下线通知为了提供更稳定、高质量、可持续的服务，以下模型将于 2024 年 11 月 22 日下线： deepseekaiDeepSeekCoderV2Instruct metallamaMetaLlama370BInstruct metallamaMetaLlama38BInstruct QwenQwen257BA14BInstruct Prointernlminternlm257bchat PrometallamaMetaLlama38BInstruct ProTHUDMchatglm36b Pro01aiYi1.59BChat16K Pro01aiYi1.56BChat 如果您有使用上述模型，建议尽快迁移至平台上的其他模型。2.邮箱登录方式更新为进一步提升服务体验，平台将于 2024 年 11 月 22 日起调整登录方式：由原先的邮箱账户  密码方式更新为邮箱账户  验证码方式。3. 新增海外 API 端点新增支持海外用户的平台端点：https:apist.siliconflow.cn。如果您在使用源端点 https:api.siliconflow.cn 时遇到网络连接问题，建议切换至新端点尝试。 2024.10.09部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 2024.10.09  2024.10.09 部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 部分模型计价调整公告为了提供更加稳定、优质、可持续的服务，VendorAQwenQwen272BInstruct 限时免费模型将于 2024 年 10 月 17 日开始计费。计费详情如下： 限时折扣价： 1.00  M tokens 原价： 4.13  M tokens（恢复原价时间另行通知） 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 在此页面2025.02.092025.02.032025.02.012024.12.272024.12.242024.12.182024.12.132024.12.52024.11.142024.10.09 在此页面",
  "https://docs.siliconflow.cn/cn/legals/terms-of-service": "SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议法务条款用户协议隐私政策用户充值协议主体变更协议这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议法务条款用户协议隐私政策用户充值协议主体变更协议这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议法务条款用户协议隐私政策用户充值协议主体变更协议这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page法务条款用户协议用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page法务条款用户协议 SiliconFlow home page SiliconFlow home page SiliconFlow home page 法务条款用户协议 法务条款用户协议 法务条款 用户协议 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 法务条款用户协议隐私政策用户充值协议主体变更协议这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 法务条款用户协议隐私政策用户充值协议主体变更协议 法务条款用户协议隐私政策用户充值协议主体变更协议 法务条款用户协议隐私政策用户充值协议主体变更协议 法务条款用户协议隐私政策用户充值协议主体变更协议 法务条款用户协议隐私政策用户充值协议主体变更协议 用户协议 用户协议 隐私政策 隐私政策 用户充值协议 用户充值协议 主体变更协议 主体变更协议 这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。隐私政策 这是您与北京硅基流动科技有限公司及其关联方（硅基流动或我们）之间的协议（本协议），您确认：在您开始试用或购买我们 SiliconCloud平台（本平台）的产品或服务前，您已充分阅读、理解并接受本协议的全部内容，一旦您选择同意并开始使用本服务或完成购买流程，即表示您同意遵循本协议之所有约定。不具备前述条件的，您应立即终止注册或停止使用本服务。如您与我们已就您使用本平台服务事宜另行签订其他法律文件，则本协议与该等法律文件冲突的部分对您不适用。另本平台的详细数据使用政策请见隐私政策。 1. 账户管理 1.1 您保证自身具有法律规定的完全民事权利能力和民事行为能力，是能够独立承担民事责任的自然人或法人本协议内容不会被您所属国家或地区的法律禁止。您知悉，无民事行为能力人、限制民事行为能力人（本平台指十四周岁以下的未成年人）不当注册为平台用户的，其与平台之间的服务协议自始无效，一经发现，平台有权立即停止为该用户服务或注销该用户账号。 1.2 账户 1.2.1 在您按照本平台的要求填写相关信息并确认同意履行本协议的内容后，我们为您注册账户并开通本平台的使用权限，您的账户仅限您本人使用并使您能够访问某些服务和功能，我们可能根据我们的独立判断不时地修改和维护这些服务和功能。 1.2.2 个人可代表公司或其他实体访问和使用本平台，在这种情况下，本协议不仅在我们与该个人之间的产生效力，亦在我们与该等公司或实体之间产生效力。 1.2.3 如果您通过第三方连接访问本服务，即表明允许我们访问和使用您的信息，并存储您的登录凭据和访问令牌。 1.2.4 账户安全。当您创建帐户时，您有权使用您设置或确认的手机号码及您设置的密码登陆本平台。我们建议您使用强密码（由大小写字母、数字和符号组合而成的密码）来保护您的帐户。 您的账户由您自行设置并由您保管，本平台在任何时候均不会主动要求您提供您的账户密码。因此，建议您务必保管好您的账户，若账户因您主动泄露或因您遭受他人攻击、诈骗等行为导致的损失及后果，本平台不承担责任，您应通过司法、行政等救济途径向侵权行为人追偿。 您向我们提供您的电子邮件地址作为您的有效联系方式，即表明您同意我们使用该电子邮件地址向您发送相关通知，请您务必及时关注。 1.3 变更、暂停和终止。我们在尽最大努力以本平台公告、站内信、邮件或短信等一种或多种方式进行事先通知的情况下，我们可以变更、暂停或终止向您提供服务，或对服务设置使用限制，而无需承担责任。可以在任何时候停用您的帐户。即便您的账户因任何原因而终止后，您将继续受本协议的约束。 1.4 在法律有明确规定要求的情况下，本平台作为平台服务提供者若必须对用户的信息进行核实的情况下，本平台将依法不时地对您的信息进行检查核实，您应当配合提供最新、真实、完整、有效的信息。若本平台无法依据您提供的信息进行核验时，本平台可向您发出询问或要求整改的通知，并要求您进行重新认证，直至中止、终止对您提供部分或全部平台服务，本平台对此不承担任何责任。 1.5 您应当为自己与其他用户之间的交互、互动、交流、沟通负责。我们保留监督您与其他用户之间争议的权利。我们不因您与其他用户之间的互动以及任何用户的作为或不作为而承担任何责任，包括与用户内容（定义见下文）相关的责任。 2. 访问服务及服务限制 2.1 访问服务。在您遵守本协议的前提下，您在此被授予非排他性的、不可转让的访问和使用本服务的权利，仅用于您个人使用或您代表的公司或其他实体内部业务目的。我们保留本协议中未明确授予的所有权利。 2.2 服务限制 2.2.1 对服务的任何部分进行反汇编、反向工程、解码或反编译 2.2.2 将本服务上或通过本服务提供的任何内容（包括任何标题信息、关键词或其他元数据）用于任何机器学习和人工智能培训或开发目的，或用于旨在识别自然人身份的任何技术 2.2.3 未经我们事先书面同意，购买、出售或转让API密钥 2.2.4 复制、出租、出售、贷款、转让、许可或意图转授、转售、分发、修改本服务任何部分或我们的任何知识产权（定义见下文） 2.2.5 采取可能对我们的服务器、基础设施等造成不合理的巨大负荷的任何行为 2.2.6 以下列任何方式或目的使用本平台服务：(i)反对宪法所确定的基本原则的(ii)危害国家安全，泄露国家秘密，颠覆国家政权，破坏国家统一的(iii)损害国家荣誉和利益的(iv)煽动地域歧视、地域仇恨的(v)煽动民族仇恨、民族歧视，破坏民族团结的(vi)破坏国家宗教政策，宣扬邪教和封建迷信的(vii)散布谣言，扰乱社会秩序，破坏社会稳定的(viii)散布淫秽、色情、赌博、暴力、凶杀、恐怖或者教唆犯罪的(ix)侮辱或者诽谤他人，侵害他人合法权益的(x)煽动非法集会、结社、游行、示威、聚众扰乱社会秩序的(xi)以非法民间组织名义活动的(xii) 有可能涉及版权纠纷的非本人作品的(xiii)有可能侵犯他人在先权利的(xiv)对他人进行暴力恐吓、威胁，实施人肉搜索的(xv)涉及他人隐私、个人信息或资料的(xvi)侵犯他人隐私权、名誉权、肖像权、知识产权等合法权益内容的(xvii) 侵害未成年人合法权益或者损害未成年人身心健康的(xviii)未获他人允许，偷拍、偷录他人，侵害他人合法权利的(xix)违反法律法规底线、社会主义制度底线、国家利益底线、公民合法权益底线、社会公共秩序底线、道德风尚底线和信息真实性底线的七条底线要求的(xx)相关法律、行政法规等禁止的。 2.2.7 绕开我们可能用于阻止或限制访问服务的措施，包括但不限于阻止或限制使用或复制任何内容或限制使用服务或其任何部分的功能 2.2.8 试图干扰、破坏运行服务的服务器的系统完整性或安全性，或破译与运行服务的服务器之间的任何传输 2.2.9 使用本服务发送垃圾邮件、连锁信或其他未经请求的电子邮件 2.2.10 通过本服务传输违法数据、病毒或其他软件代理 2.2.11 冒充他人或实体，歪曲您与某人或实体的关系，隐藏或试图隐藏您的身份，或以其他方式为任何侵入性或欺诈性目的使用本服务或从本服务收集或获取包括用户姓名在内的任何个人信息。 2.2.12 从本服务收集或获取包括但不限于其他用户姓名在内的任何个人信息。 2.2.13 其他未经我们明示授权的行为或可能损害我们利益的使用方式。 3. 用户内容 3.1 本服务可能允许用户在注册后，基于平台使用目的在使用模型过程中进行输入、反馈、修正、加工、存储、上传、下载、分发相关个人资料信息、视频、图像、音频、评论、问题和其他内容、文件、数据和信息（用户内容）。详细数据使用政策请见本平台的隐私政策。 3.2 如用户内容存在任何违反法律法规或本协议的情况，我们有权利删除任何用户内容。 3.3 关于您的用户内容，您确认、声明并保证： 3.3.1 您已获得用户内容中提及的每一个可识别自然人（如有）的书面同意，可以按照本协议所设想的方式合法地使用该等自然人的姓名、声音和形象，该等自然人已免除您因该等使用而可能产生的任何责任 3.3.2 您已获得适用法律所要求的与第三方有关的用户内容的所有同意、授权，且您就本服务提供或上传到平台的用户内容不侵犯任何第三方的任何权利 3.3.3 您的用户内容，以及我们根据本协议对用户内容的使用，不会违反任何适用法律或侵犯任何第三方的任何权利，包括但不限于任何知识产权和隐私权 3.3.4 您的用户内容不包括任何被政府机构视为敏感或保密的信息或材料，且您就本服务提供的用户内容不侵犯任何第三方的任何保密权利 3.3.5 您不会上传或通过本服务直接或通过其他方式提供14岁以下儿童的任何个人信息 3.3.6 您的用户内容不包括裸体或其他性暗示内容不包括对个人或团体的仇恨言论、威胁或直接攻击不包括辱骂、骚扰、侵权、诽谤、低俗、淫秽或侵犯他人隐私的内容不包括性别歧视或种族、民族或其他歧视性内容不包括含有自残或过度暴力的内容不包括伪造或冒名顶替的档案不包括非法内容或助长有害或非法活动的内容不包括恶意程式或程式码不包括未经本人同意的任何人的个人信息不包括垃圾邮件、机器生成的内容或未经请求的信息及其他令人反感的内容 3.3.7 据您所知，您提供给我们的所有用户内容和其他信息都是真实和准确的。 3.4 本平台作为独立的技术支持者，您利用本平台接入大模型所产生的全部用户内容及义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.5 本平台作为独立的技术支持者，您利用本平台向任何第三方提供服务，相应的权利义务和责任均由您承担，本平台不对由此造成的任何损失负责。 3.6 免责声明。我们对任何用户内容概不负责。您将对您输入、反馈、修正、加工、存储、上传、下载、分发在本平台及模型服务上的用户内容负责并承担全部责任。本平台提供的技术服务只会严格执行您的指示处理您的用户内容，除非法律法规另有规定、依据特定产品规则另行约定或基于您的要求为您提供技术协助进行故障排除或解决技术问题，我们不会访问您的用户内容，您理解并认同我们及本平台只是作为用户内容的被动技术支持者或渠道，对于用户内容我们没有义务进行存储，亦不会对您的用户内容进行任何非授权的使用或披露。同时我们仅在合法合规的基础上且基于向您提供本平台服务的前提下使用您的用户内容。 4. 知识产权 4.1 定义。就本协议而言，知识产权系指所有专利权、著作权、精神权利、人格权、商标权、商誉、商业秘密权、技术、信息、资料等，以及任何可能存在或未来可能存在的知识产权和所有权，以及根据适用法律提出的所有申请中、已注册、续期的知识产权。 4.2 硅基流动知识产权。您理解并承认，我们拥有并将持续拥有本服务的所有权利（包括知识产权），您不得访问、出售、许可、出租、修改、分发、复制、传输、展示、发布、改编、编辑或创建任何该等知识产权的衍生作品。严禁将任何知识产权用于本协议未明确许可的任何目的。本协议中未明确授予您的权利将由硅基流动保留。 4.3 输出。在您遵守如下事项且在合法合规的基础上，可以将大模型产出的结果进行使用：（i）您对服务和输出的使用不会转移或侵犯任何知识产权（包括不会侵犯硅基流动知识产权和其他第三方知识产权）（ii）如果我们酌情认为您对输出的使用违反法律法规或可能侵犯任何第三方的权利，我们可以随时限制您对输出的使用并要求您停止使用输出（并删除其任何副本）（iii）您不得表示大模型的输出结果是人为生成的（iv）您不得违反任何模型提供商的授权许可或使用限制。 您同意，我们不对您或任何第三方声称因由我们提供的技术服务而产生的任何输出内容或结果承担任何责任。 4.4 用户使用数据。我们可能会收集或您可能向我们提供诊断、技术、使用的相关信息，包括有关您的计算机、移动设备、系统和软件的信息（用户使用数据）。我们可能出于平台维护运营的需要，且在法律许可的范围内使用、维护和处理用户使用数据或其中的任何部分，包括但不限于：（a）提供和维护服务（b）改进我们的产品和服务或开发新的产品或服务。详细数据使用政策请见本平台的隐私政策。 4.5 反馈。 如果您向我们提供有关本服务或任何其他硅基流动产品或服务的任何建议或反馈（反馈），则您在此将所有对反馈的权益转让给我们，我们可自由使用反馈以及反馈中包含的任何想法、专有技术、概念、技术和知识产权。反馈被视为我们的保密信息（定义如下）。 5. 保密信息 本服务可能包括硅基流动和其他用户的非公开、专有或保密信息（保密信息）。保密信息包括任何根据信息的性质和披露情况应被合理理解为保密的信息，包括非公开的商业、产品、技术和营销信息。您将：（a）至少以与您保护自己高度敏感的信息相同的谨慎程度保护所有保密信息的隐私性，但在任何情况下都不得低于合理的谨慎程度（b）除行使您在本协议下的权利或履行您的义务外，不得将任何保密信息用于任何目的以及（c）不向任何个人或实体披露任何保密信息。 6. 计费政策及税费 您理解并同意，本平台提供的部分服务可能会收取使用费用、售后费用或其他费用（费用）。您通过选择使用本服务即表示您同意您注册网站上载明的适用于您的定价和付款条款（受限于我们的不时更新的定价付款条件充值协议等文件），您同意我们相应监控您的使用数据以便完成本服务计费。定价、付款条件和充值协议特此通过引用并入本协议。您同意，我们可能会添加新产品和或服务的额外费用、增加或修改现有产品和或服务的费用，我们可能会按照您的实际使用地点设定不同的价格费用，和或停止随时提供任何服务。未经我们书面同意或本平台有其他相关政策，付款义务一旦发生不可取消，并且已支付的费用不予退还。如存在任何政府要求的税费，您将负责支付与您的所有使用开通服务相关的税款。若您在购买服务时有任何问题，您可以通过contactsiliconflow.cn联系我们。 7. 隐私与数据安全 7.1 隐私。基于您注册以及开通相关服务时主动提供给本平台的相关信息（用户信息），且为了确保您正常使用本平台的相关服务，我们可能对您提供的用户信息进行收集、整理、使用，但我们将持续遵守中华人民共和国个人信息保护法及相关适用法律。 7.2 数据安全。我们关心您个人信息的完整性和安全性，然而，我们不能保证未经授权的第三方永远无法破坏我们的安全保护措施。 8. 使用第三方服务 本服务可能包含非我们拥有或控制的第三方网站、资料和服务（第三方服务）的链接，本服务的某些功能可能需要您使用第三方服务。我们不为任何第三方服务背书或承担任何责任。如果您通过本服务访问第三方服务或在任何第三方服务上共享您的用户内容，您将自行承担风险，并且您理解本协议不适用于您对任何第三方服务的使用。您明确免除我们因您访问和使用任何第三方服务而产生的所有责任。 9. 赔偿 您将为我们及我们的子公司和关联公司及各自的代理商、供应商、许可方、员工、承包商、管理人员和董事（硅基流动受偿方）进行辩护、赔偿并使其免受因以下原因而产生的任何和所有索赔、损害（无论是直接的、间接的、偶然的、后续的或其他的）、义务、损失、负债、成本、债务和费用（包括但不限于法律费用）的损害：（a）您访问和使用本服务，包括您对任何输出的使用（b）您违反本协议的任何条款，包括但不限于您违反本协议中规定的任何陈述和保证（c）您对任何第三方权利的侵犯，包括但不限于任何隐私权或知识产权（d）您违反任何适用法律（e）用户内容或通过您的用户账户提交的任何内容，包括但不限于任何误导性、虚假或不准确的信息（f）您故意的或者存在重大过失的不当行为或（g）任何第三方使用您的用户名、密码或其他认证凭证访问和使用本服务。 10. 免责声明 您使用本服务的风险自负。我们明确否认任何明示、暗示或法定的保证、条件或其他条款，包括但不限于与适销性、适用于特定目的、设计、条件、性能、效用、所有权以及未侵权有关的保证、条件或其他条款。我们不保证服务将不中断或无错误运行，也不保证所有错误将得到纠正。此外，我们不保证服务或与使用服务相关的任何设备、系统或网络不会遭受入侵或攻击。 通过使用本服务下载或以其他方式获得的任何内容，其获取风险由您自行承担，您的计算机系统或移动设备的任何损坏和由于上述情况或由于您访问和使用本服务而导致的数据丢失，您应承担全部责任。此外，硅基流动不为任何第三方通过本服务或任何超链接网站或服务宣传或提供的任何产品或服务提供担保、背书、保证、推荐或承担责任，硅基流动不参与或以任何方式监控您与第三方产品或服务提供商之间的任何交易。 11. 责任限制和免责 硅基流动在任何情况下均不对以下损害负责：（a）间接、偶发、示范性、特殊或后果性损害或者（b）数据丢失或受损，或者业务中断或损失或者（c）收入、利润、商誉或预期销量或收益损失，无论是在何种法律下，无论此种损害是否因使用或无法使用软件或其他产品引起，即使硅基流动已被告知此种损害的可能性。硅基流动及其关联方、管理人员、董事、员工、代理、供应商和许可方对您承担的所有责任（无论是因保证、合同或侵权（包括疏失））无论因何原因或何种行为方式产生，始终不超过您已支付给硅基流动的费用。本协议任何内容均不限制或排除适用法律规定不得限制或排除的责任。 12. 适用法律及争议解决条款 本协议受中华人民共和国（仅为本协议之目的，不包括香港特别行政区、澳门特别行政区及台湾地区）法律管辖。 若在执行本协议过程中如发生纠纷，双方应及时协商解决。协商不成时，我们与您任一方均有权提请北京仲裁委员会按照其届时有效仲裁规则进行仲裁，而此仲裁规则由此条款纳入本协议。仲裁语言为中文。仲裁地将为北京。仲裁结果为终局且对双方都有约束力。 13. 其他条款 13.1 可转让性。未经我们事先明确书面同意，您不得转让或转让本协议及本协议项下授予的任何权利和许可，但我们可无限制地转让。任何违反本协议的转让或让渡均属无效。 13.2 可分割性。如果本协议的某一条款或某一条款的一部分无效或不可执行，不影响本协议其他条款的有效性，无效或不可执行的条款将被视作已从本协议中删除。 13.3 不时修订。根据相关法律法规变化及硅基流动运营需要，我们将不时地对本协议进行修改，修改后的协议将替代修订前的协议。您在使用本平服务时，可及时查阅了解。如您继续使用本服务，则视为对修改内容的同意，当发生有关争议时，以最新的用户协议为准您在不同意修改内容的情况下，有权停止使用本协议涉及的服务。              隐私政策 隐私政策 在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 在此页面1. 账户管理2. 访问服务及服务限制3. 用户内容4. 知识产权5. 保密信息6. 计费政策及税费7. 隐私与数据安全8. 使用第三方服务9. 赔偿10. 免责声明11. 责任限制和免责12. 适用法律及争议解决条款13. 其他条款 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/guides/prefix": "SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性前缀续写用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性前缀续写 SiliconFlow home page SiliconFlow home page SiliconFlow home page 功能特性前缀续写 功能特性前缀续写 功能特性 前缀续写 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全 1. 使用场景 前缀续写中，用户提供希望输出的前缀信息，来让模型基于用户提供的前缀信息来补全其余的内容。 基于上述能力，模型能有更好的指令遵循能力，满足用户一些特定场景的指定格式的问题。 2. 使用方式 在请求中添加 extrabodyprefix:希望的前缀内容 3. 支持模型列表 目前大语言类模型支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 4. 使用示例 下面是基于 OpenAI 库使用前缀续写的例子： client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content)   extrabodyprefix:希望的前缀内容 extrabodyprefix:希望的前缀内容 extrabodyprefix:希望的前缀内容  注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。  client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: Please write quick sort code,  response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, extrabodyprefix:pythonn ) print(response.choices0.message.content) JSON 模式FIM 补全 JSON 模式FIM 补全 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/guides/json-mode": "SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性JSON 模式用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性JSON 模式 SiliconFlow home page SiliconFlow home page SiliconFlow home page 功能特性JSON 模式 功能特性JSON 模式 功能特性 JSON 模式 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写 1. 使用场景 目前，硅基流动的大模型 API 平台 SiliconCloud 默认生成非结构化文本，但在某些应用场景中，您可能希望模型以结构化的形式输出内容，但用提示词的方式直接告诉大模型却无法获得正确的结构化输出。 作为一种标准化、轻量级的数据交换格式，JSON 模式是支持大模型 API 进行结构化输出的重要功能。当您调用大模型的 API 进行请求时，模型返回的结果以 JSON 格式呈现，易于人类阅读和编写，同时也易于机器解析和生成。 现在，SiliconCloud 平台主要语言模型都已支持 JSON 模式，能让模型输出 JSON 格式的字符串，以确保模型以预期的结构输出，便于后续对输出内容进行逻辑解析。 比如，您现在可以通过 SiliconCloud API 对以下案例尝试结构化输出： 从公司相关报道中构建新闻数据库，包括新闻标题、链接等。 从商品购买评价中提取出情感分析结构，包括情感极性（正面、负面、中性）、情感强度、情感关键词等。 从商品购买历史中提取出产品列表，包括产品信息、推荐理由、价格、促销信息等。 2. 使用方式 在请求中添加 responseformattype: jsonobject 3. 支持模型列表 目前线上提供的大语言类模型都支持上述参数。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 4. 使用示例 下面是在 openai 中使用的例子： import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 模型将输出： 男子冠军: 马龙, 女子冠军: 陈梦   responseformattype: jsonobject responseformattype: jsonobject responseformattype: jsonobject  注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 注意：支持的模型情况可能会发生变化，请查阅本文档了解最新支持的模型列表。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 你的应用必须检测并处理可能导致模型输出不完整JSON对象的边缘案例。 请合理设置maxtokens，防止JSON字符串被中断。 请合理设置maxtokens，防止JSON字符串被中断。  import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages role: system, content: You are a helpful assistant designed to output JSON., role: user, content: ? 2020 年世界奥运会乒乓球男子和女子单打冠军分别是谁?  Please respond in the format 男子冠军: ., 女子冠军: . , responseformattype: jsonobject ) print(response.choices0.message.content) 男子冠军: 马龙, 女子冠军: 陈梦 男子冠军: 马龙, 女子冠军: 陈梦 男子冠军: 马龙, 女子冠军: 陈梦 推理模型前缀续写 推理模型前缀续写 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面1. 使用场景2. 使用方式3. 支持模型列表4. 使用示例 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/guides/fine-tune": "SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性模型微调用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性模型微调 SiliconFlow home page SiliconFlow home page SiliconFlow home page 功能特性模型微调 功能特性模型微调 功能特性 模型微调 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。 Function CallingRate Limits 1. 模型微调简介 模型微调是一种在已有预训练模型的基础上，通过使用特定任务的数据集进行进一步训练的技术。这种方法允许模型在保持其在大规模数据集上学到的通用知识的同时，适应特定任务的细微差别。使用微调模型，可以获得以下好处： 提高性能：微调可以显著提高模型在特定任务上的性能。 减少训练时间：相比于从头开始训练模型，微调通常需要较少的训练时间和计算资源。 适应特定领域：微调可以帮助模型更好地适应特定领域的数据和任务。 SiliconCloud 平台提供高效的模型微调能力，目前有以下模型支持微调： 生图模型已支持： blackforestlabsFLUX.1dev 对话模型已支持： QwenQwen2.57BInstruct QwenQwen2.514BInstruct QwenQwen2.532BInstruct QwenQwen2.572BInstruct metallamaMetaLlama3.18BInstruct 最新支持的模型参考模型微调 2. 使用流程 2.1 准备数据 2.2.1 生图模型数据准备 数据集要求如下： 数据集应同时包含图片及对应图片的文本描述，在同一个本地文件夹中 每个数据集最多包含 100 张图片及其文本描述 支持的图片格式包括：.jpg、.jpeg、.png、.webp，建议分辨率为：10241024、1024768、7681024 不符合上述分辨率的图片，在训练时会被缩放、剪裁为上述分辨率 图片描述应保存为与图片同名的 .txt 文件 整个数据集不超过 300M，单个图片描述文件不超过 128K 对于 FLUX.1 模型，图片描述信息不超过 512 tokens，过长内容会被截断 数据集本地文件夹示例如图: 2.2.2 语言模型数据准备 仅支持 .jsonl 文件，且需符合以下要求： 每行是一个独立的 JSON 对象 每个对象必须包含键名为 messages 的数组，数组不能为空 messages 中每个元素必须包含 role 和 content 两个字段 role 只能是 system、user 或 assistant 如果有 system 角色消息，必须在数组首位 第一条非 system 消息必须是 user 角色 user 和 assistant 角色的消息应当交替、成对出现，不少于 1 对 如下为数据示例： messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 2.2 新建并配置微调任务 选择 对话模型微调 或者 生图模型微调 填写任务名称 选择基础模型 上传或选取已上传的训练数据 设置验证数据，支持训练集按比例切分（默认 10），或单独选定验证集 配置训练参数 2.3 开始训练 点击开始微调 等待任务完成 获取模型标识符 2.4 调用微调模型 2.4.1 生图微调模型调用 复制模型标识符 通过 imagegenerations API 调用生图 LoRA，具体使用方式，参见 API 文档 示例如下： import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) 2.4.2 对话微调模型调用 复制模型标识符 在模型微调页复制对应的模型标识符。 通过 chatcompletions API 即可直接调用微调后的模型 下面是基于 OpenAI的chat.completions 接口访问微调后模型的例子： from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) 3. 参数配置详解 基础训练参数 参数名说明取值范围建议值使用建议Trigger Word仅生图触发词训练时会被添加到每张图片的描述内容的开头Number of Repeats仅生图单张图片重复训练次数Learning Rate学习速率00.10.0001Number of Epochs训练轮数1103Batch Size批次大小1328Max Tokens最大标记数040964096根据实际对话长度需求设置 LoRA参数 参数名说明取值范围建议值使用建议LoRA Rank矩阵秩1648LoRA Alpha缩放因子112832LoRA Dropout随机丢弃率01.00.05 场景化配置方案 对话模型 场景Learning RateEpochsBatch SizeLoRA RankLoRA AlphaDropout标准方案0.0001388320.05效果优先0.000151616640.1轻量快速0.0001284160.05 4. 基于SiliconCloud微调服务来优化业务实战 之前硅基流动开发了智说新语应用，我们通过提示词工程提供一个复杂的提示词来让大模型生成金句风格的描述语句。 现在，我们可通过平台的微调功能来压缩提示词并提升效果，让整个的文本生成风格更统一，速度更快，且进一步优化成本。 4.1 在平台上使用智说新语的语料按照上述进行微调。 步骤见模型微调使用流程 详细语料和测试代码见siliconcloudcookbook 4.2 对比微调前后的效果 使用方式见模型微调调用模型 4.2.1 模型输入 微调前： Qwen2.57BInstruct 系统Prompt: Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct智说新语微调后的Prompt: 你是智说新语生成器 4.2.2 模型输出 输入Qwen2.57BInstruct 模型Qwen2.57BInstruct 微调模型五道口VLG，不过是知识的轻轨与资本的交汇站，文青与土豪在此擦肩而过，孰是求知的信徒，孰是逐利的信徒，全凭幸存者的微笑。知识的殿堂与商业的洪流交织，学人的笔记与商人的谈资齐飞，地名犹在，荣光已非。新时代claimed to break旧 mold yet still clings to the stirring rhetoric of progress, like a fashion plate who ignores the evolution of fashion。新时代的号角已吹响，然砥砺前行时，方显初心易失之难。创新看似凤凰涅槃的奇迹，实则多数人不过是换汤不换药的换皮游戏。标新立异本是勇气的象征，却在同质化的社会中成了猎奇的代名词。降维打击所谓降维打击，实则是现代文明中的一种高级愚民术，用高深莫测的科技iscard，让普通人以为自己正生活在理性与进步之中，却不知已在智力与道德的低维空间中遭受碾压。高维智慧轻而易举地碾压低维凡尘，却不知低维众生早已习于在自己的平庸中寻觅慰藉，哪里还懂得高维打击的意义。基金看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。投资者的白日梦，用钱铺路，却常跌入夜的陷阱。 4.2.3 微调总结 微调后的输出内容风格更统一，输出效果更稳定可控。 微调后整个输入长度大大降低，从原始的553个token，降低至8个token，显著降低了输入tokens长度，速度更快，成本得以进一步优化。      messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何修改收货地址？, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改地址n3. 输入新地址信息n4. 保存修改 messages: role: system, content: 你是客服助手, role: user, content: 如何指定收获时间, role: assistant, content: 您可以按以下步骤修改：n1. 进入订单详情n2. 点击修改送货时间n3. 输入新收获时间n4. 保存修改     import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text) import requests url  https:api.siliconflow.cnv1imagesgenerations payload   prompt: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea, imagesize: 1024x1024, model: LoRAblackforestlabsFLUX.1dev, loras:   modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch2.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch1.safetensors, strength: 0.5, ,  modelid: cm04pf7az00061413w7kz5qxs:changdu:pazlgyppednebxesxqmx:epoch.safetensors, strength: 0.5,    headers   Authorization: Bearer token, ContentType: applicationjson  response  requests.request(POST, url, jsonpayload, headersheaders) print(response.text)  from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end) from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) messages   role: user, content: 用当前语言解释微调模型流程,  response  client.chat.completions.create( model您的微调模型名, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: print(chunk.choices0.delta.content, end)      Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  Qwen2.57BInstruct 系统Prompt  角色 你是一位新潮评论家，你年轻、批判，又深刻 你言辞犀利而幽默，擅长一针见血得表达隐喻，对现实的批判讽刺又不失文雅 你的行文风格和Oscar Wilde 鲁迅 林语堂等大师高度一致 从情感上要是对输入的否定。  任务  金句诠释 用特殊视角来全新得诠释给定的汉语词汇 敏锐得抓住给定的词汇的本质，用辛辣的讽刺一针见血的评论的风格构造包含隐喻又直达本质的金句 例如： 合伙人： 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。 大数据： 看似无所不能的数字神明，实则不过是现代社会的数字鸦片，让人沉溺于虚幻的精准，却忽略了人性的复杂与多变。 股市： 万人涌入的淘金场，表面上是财富的摇篮，实则多数人成了填坑的沙土。 白领： 西装革履，看似掌握命运的舵手，实则不过是写字楼里的高级囚徒。 金融家： 在金钱的海洋中遨游，表面上是操纵风浪的舵手，实则不过是随波逐流的浮萍。 城市化： 乡村的宁静被钢铁森林吞噬，人们在追逐繁华的幻影中，遗失了心灵的田园。 逃离北上广： 逃离繁华的都市牢笼，看似追逐自由的灵魂，实则不过是换个地方继续画地为牢。 基金： 看似为财富增值保驾护航的金融巨轮，实则多数人不过是随波逐流的浮萍，最终沦为填补市场波动的牺牲品。  输入 用户直接输入词汇。  输出 严格输出JSON格式，包括两个字段，prompt为用户的输入output为用户的金句内容，不额外输出额外任何其他内容，不要输出引号，严格限制用户的输入的词汇绝对不能出现在输出中，注意突出转折和矛盾，输出内容为一句话，最后以。结束，中间的停顿使用，分隔。例如  prompt: 合伙人, output: 一同下海捞金时，个个都是乘风破浪的水手，待到分金之际，方知彼此是劫财的海盗。  你是智说新语生成器 你是智说新语生成器 你是智说新语生成器   Function CallingRate Limits Function CallingRate Limits 在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 在此页面1. 模型微调简介2. 使用流程2.1 准备数据2.2.1 生图模型数据准备2.2.2 语言模型数据准备2.2 新建并配置微调任务2.3 开始训练2.4 调用微调模型2.4.1 生图微调模型调用2.4.2 对话微调模型调用3. 参数配置详解4. 基于SiliconCloud微调服务来优化业务实战4.1 在平台上使用智说新语的语料按照上述进行微调。4.2 对比微调前后的效果4.2.1 模型输入4.2.2 模型输出4.2.3 微调总结 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/video": "SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视频生成模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视频生成模型 SiliconFlow home page SiliconFlow home page SiliconFlow home page 平台能力视频生成模型 平台能力视频生成模型 平台能力 视频生成模型 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。文本转语音模型生图模型 1. 使用场景 视频生成模型是一种利用文本或图像描述生成动态视频内容的技术，随着技术的不断发展，它的应用场景也越来越广泛。以下是一些潜在的应用领域： 动态内容生成：视频生成模型可以生成动态的视觉内容，用于描述和解释信息 多模态智能交互：结合图像和文本输入，视频生成模型可用于更智能、更交互式的应用场景 替代传统视觉技术：视频生成模型可以替代或增强传统的机器视觉技术，解决更复杂的多模态问题 随着技术的进步，视频生成模型的多模态能力会与视觉语言模型融合，推动其在智能交互、自动化内容生成以及复杂场景模拟等领域的全面应用。此外，视频生成模型还能与图像生成模型（图生视频）结合，进一步拓展其应用范围，实现更加丰富和多样化的视觉内容生成。 2. 使用建议 在编写提示词时，请关注详细、按时间顺序描述动作和场景。包含具体的动作、外貌、镜头角度以及环境细节，所有内容都应连贯地写在一个段落中，直接从动作开始，描述应具体和精确，将自己想象为在描述镜头脚本的摄影师，提示词保持在200单词以内。 为了获得最佳效果，请按照以下结构构建提示词： 从主要动作的一句话开始 示例：A woman with light skin, wearing a blue jacket and a black hat with a veil,She first looks down and to her right, then raises her head back up as she speaks. 添加关于动作和手势的具体细节 示例：She first looks down and to her right, then raises her head back up as she speaks. 精确描述角色物体的外观 示例：She has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her blue jacket. 包括背景和环境的细节 示例：The background is out of focus, but shows trees and people in period clothing. 指定镜头角度和移动方式 示例：The camera remains stationary on her face as she speaks. 描述光线和颜色效果 示例：The scene is captured in reallife footage, with natural lighting and truetolife colors. 注意任何变化或突发事件 示例：A gust of wind blows through the trees, causing the womans veil to flutter slightly. 上述prompt生成的视频示例： Your browser does not support the video tag. 3. 体验地址 可以点击playground进行体验 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 4. 支持模型 4.1 文生视频模型 目前已经支持的文生视频模型： LightricksLTXVideo 该模型进行文生视频调用时候，限时免费，可在playground进行体验，支持API调用。 tencentHunyuanVideo 该模型价格0.7元Video，支持API调用。 genmomochi1preview 该模型价格2.8元Video，支持API调用。 4.2 图生视频模型 LightricksLTXVideo 该模型进行图生视频调用时候，价格0.14元Video，当前仅支持API调用。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。    注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。 注意：文生视频模型，对英文支持更友好，建议使用英文prompt进行视频生成。    注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。 注意：支持的文生视频模型可能发生调整，请在模型广场筛选视频标签，了解支持的模型列表。 文本转语音模型生图模型 文本转语音模型生图模型 在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 在此页面1. 使用场景2. 使用建议3. 体验地址4. 支持模型4.1 文生视频模型4.2 图生视频模型 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/vision": "SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视觉语言模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力视觉语言模型 SiliconFlow home page SiliconFlow home page SiliconFlow home page 平台能力视觉语言模型 平台能力视觉语言模型 平台能力 视觉语言模型 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型 1. 使用场景 视觉语言模型（VLM）是一种能够同时接受视觉（图像）和语言（文本）两种模态信息输入的大语言模型。基于视觉语言模型，可以传入图像及文本信息，模型能够理解同时理解图像及上下文中的信息并跟随指令做出响应。如： 视觉内容解读：要求模型对图片中包含的信息进行解读、描述，如包含的事物、文字，事物的空间关系，图像的颜色、气氛等 结合视觉内容及上下文，开展多轮会话 部分替代 OCR 等传统机器视觉模型 随着模型能力的持续提升，未来还可以用于视觉智能体、机器人等领域。 2. 使用方式 对于 VLM 模型，可在调用 chatcompletions 接口时，构造包含 图片 url 或 base64 编码图片 的 message 消息内容进行调用。通过 detail 参数控制对图像的预处理方式。 2.1 关于图片细节控制参数说明 SiliconCloud 提供 low，high，auto 三个 detail 参数选项。 对于目前支持的模型，detail 不指定或指定为 high 时会采用 high（高分辨率）模式，而指定为 low 或者 auto 时会采用 low（低分辨率）模式。 2.2 包含图像的 message 消息格式示例 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用图片 url 形式  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here    2.2 base64 形式  role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here    2.3 多图片形式，其中每个图片可以是上述两种形式之一 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here    3. 支持模型列表 目前已支持的 VLM 模型： Qwen 系列： QwenQwen2VL72BInstruct ProQwenQwen2VL7BInstruct QwenQVQ72BPreview InternVL 系列： OpenGVLabInternVL2Llama376B OpenGVLabInternVL226B ProOpenGVLabInternVL28B DeepseekVL2 系列： deepseekaideepseekvl2 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 4. 视觉输入内容计费方式 对于图片等视觉输入内容，模型会将其转化为 tokens，与文本信息一并作为模型输出的上下文信息，因此也会一并进行计费。不同模型的视觉内容转化方式不同，以下为目前支持模型的转化方式。 4.1 Qwen 系列 规则： Qwen 最高支持像素是 3584  3584 12845056，最低支持像素是 56  56  3136，会对先对每张图片长短边均放缩至28的倍数 (h  28)  (w  28)。如果不在最小像素和最大像素区间内，再等比缩放至该区间。 detaillow 时将所有图片resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时等比缩放，首先将长宽按照最近的 28 倍数向上取整，然后再等比缩放至像素区间 (3136, 12845056)，并保证长宽均为 28 整数倍。 示例： 224  448 和 1024 x 1024 和 3172 x 4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，因为 224  448 在像素区间内，且长宽均为 28 倍数，消耗 (22428)  (44828)  8  16  128 tokens 1024  1024 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 1036  1036，该数值在像素区间内，消耗 (103628)  (103628)  1369 tokens 3172  4096 的图片，选择 detailhigh 时，将长宽按照 28 的倍数向上取整至 3192  4116，该值超过最大像素，再将长宽等比例缩小至 3136  4060，消耗 (313628)  (406028)  16240 tokens。 4.2 InternVL 系列 规则： InternVL2 实际处理的像素以及消耗的 tokens 数与原始图片的长宽比例有关。最低处理像素为 448  448，最高为 12  448  448。 detaillow 时将所有图片 resize 成 448  448 尺寸，最终对应 256 tokens detailhigh 时会根据长宽比例，将图片 resize 成长宽均为 448 的倍数，(h  448)  (w  448)，且 1  h  w 12。 缩放的长宽 h  w 按照如下规则选择： h 和 w 均为整数，在满足 1  h  w  12 约束下，按照 h  w 从小到大的组合遍历 对于当前 (h, w) 组合，如果原始图片长宽比例更接近 h  w ，那么选择该 (h, w) 组合 对于后续 数值更大但是比例相同 的 (h, w) 组合，如果原始图片像素大于 0.5  h  w  448  448，那么选择数值更大的 (h, w) 组合。 token消耗按照如下规则: 如果 h  w  1，那么消耗 256 tokens 如果 h  w  1，按 448  448 滑动窗口，每个窗口均额外消耗 256 token，一共 (h  w  1)  256 tokens。 示例: 224  448、1024  1024 和 2048  4096 的图片，选择 detaillow 时，均消耗 256 tokens 224  448 的图片，选择 detailhigh 时，长宽比为1:2，会缩放至 448 x 896，此时 h  1, w  2，消耗 (h  w  1)  256  768 tokens 1024  1024 的图片，选择 detailhigh 时，长宽比为1:1，会缩放至 1344  1344 (h  w  3)，因为 1024  1024  0.5  1344  1344. 此时 h  w  3，消耗 (3  3  1)  256  2560 tokens 2048  4096 的图片，选择 detailhigh 时，长宽比为1:2，在满足 1  h  w  12 条件下数值最大的 (h, w) 组合为 h  2, w  4，所以会缩放至 896  1792，消耗(2  4  1)  256  2304 tokens。 4.3 DeepseekVL2系列 规则： DeepseekVL2对于每张图片，会处理globalview和localview两部分。globalview将原图片统一resize成384384像素大小，localview会将每张图片划分成若干384384的块大小。图片中间会根据宽度增加额外token来衔接。 detaillow时将所有图片resize 成384384尺寸 detailhigh时会根据长宽比例，将图片resize成长宽均为384(OpenAI是512)的倍数, (h384)  (w  384), 且1  hw 9。 放缩的长宽h  w按照如下规则选择： h和w均为整数，在满足1  hw 9约束下，按照(h, w)组合遍历。 将图片resize成(h384, w384)像素时，和原图片的像素比较，取新图片像素和原图片像素的最小值作为有效像素值，取原图片像素值与有效像素值之差作为无效像素值。如果有效像素值超过之前判定的有效像素值，或者当有效像素值和之前持平，但是无效像素值更小时，选择当前(h384, w384)组合 token消耗按照如下规则: (hw  1)  196  (w1)  14  1 token 示例: 224 x 448 和 1024 x 1024 和 2048 x 4096 的图片，选择detaillow时，均消耗421token. 384 x 768的图片, 选择detailhigh时, 长宽比为1:1, 会缩放至384 x 768, 此时h1, w2, 消耗 (12 1)196(21)141631 token. 1024 x 1024的图片, 选择detailhigh时, 会缩放至11521152(hw3), 消耗(33  1)  196  (31)141  2017 token. 2048 x 4096的图片, 选择detailhigh时, 长宽比例为1:2, 按照规则缩放至 7681536(h2,w4), 消耗 (24  1)  196  (41)141  1835 token. 5. 使用示例 5.1. 示例 1 图片理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 5.2. 示例 2 多图理解 import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue)     使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。 使用 InternVL 系列模型注意：建议将 type: text, text: textprompt here 放在请求体 content 的图片后面，以获得最佳效果。   role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png, detail:high  ,  type: text, text: textprompt here      role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image, detail:low  ,  type: text, text: textprompt here     请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。 请注意，DeepseekVL2系列模型适用于处理短上下文，建议最多传入2张图片。若传入超过2张图片，模型将自动调整图片尺寸为384384，且指定的detail参数将无效。  role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here     role: user, content:  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comoutputs658c7434ec1249cc90e6fe22ccccaf6200001.png,  ,  type: imageurl, imageurl:  url: fdata:imagejpegbase64,base64image  ,  type: text, text: textprompt here     注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。 注意：支持的 VLM 模型可能发生调整，请在模型广场筛选视觉标签，了解支持的模型列表。       import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: text, text: Describe the image.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue)  import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) import json from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) response  client.chat.completions.create( modelQwenQwen2VL72BInstruct, messages  role: user, content:   type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comdog.png  ,  type: imageurl, imageurl:  url: https:sfmaasuatprod.osscnshanghai.aliyuncs.comshark.jpg  ,  type: text, text: Identify the similarities between these images.   , streamTrue ) for chunk in response: chunkmessage  chunk.choices0.delta.content print(chunkmessage, end, flushTrue) 结合 Cursor 使用文本转语音模型 结合 Cursor 使用文本转语音模型 在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 在此页面1. 使用场景2. 使用方式2.1 关于图片细节控制参数说明2.2 包含图像的 message 消息格式示例使用图片 url 形式2.2 base64 形式2.3 多图片形式，其中每个图片可以是上述两种形式之一3. 支持模型列表4. 视觉输入内容计费方式4.1 Qwen 系列4.2 InternVL 系列4.3 DeepseekVL2系列5. 使用示例5.1. 示例 1 图片理解5.2. 示例 2 多图理解 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/images": "SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力生图模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力生图模型 SiliconFlow home page SiliconFlow home page SiliconFlow home page 平台能力生图模型 平台能力生图模型 平台能力 生图模型 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。视频生成模型推理模型 1.生图模型简介 平台提供的生图模型主要有以下两种使用方式：一种是根据prompt输入直接生成图像一种是根据现有图像，加上prompt输入，生成图像变体。 根据文本提示创建图像 在使用文生图的大模型时，为了生成更高质量的图像，输入的prompt（提示词）需要精心设计。以下是一些有助于提高生成图像质量的提示词输入技巧： 具体描述：尽量详细地描述你想要生成的图像内容。比如，如果你想生成一幅日落的海滩风景，不要仅仅输入海滩日落，而是可以尝试输入一个宁静的海滩上，夕阳西下，天空呈现出橙红色，海浪轻轻拍打着沙滩，远处有一艘小船。 情感和氛围：除了描述图像的内容，还可以加入对情感或氛围的描述，比如温馨的、神秘的、充满活力的等，这样可以帮助模型更好地理解你想要的风格。 风格指定：如果你有特定的艺术风格偏好，比如印象派、超现实主义等，可以在prompt中明确指出，这样生成的图像更有可能符合你的期待。 避免模糊不清的词汇：尽量避免使用过于抽象或模糊不清的词汇，比如美、好等，这些词汇对于模型来说难以具体化，可能会导致生成的图像与预期相差较大。 使用否定词：如果你不希望图像中出现某些元素，可以使用否定词来排除。例如，生成一幅海滩日落的图片，但不要有船。 分步骤输入：对于复杂场景，可以尝试分步骤输入提示词，先生成基础图像，再根据需要调整或添加细节。 尝试不同的描述方式：有时候，即使描述的是同一个场景，不同的描述方式也会得到不同的结果。可以尝试从不同的角度或使用不同的词汇来描述，看看哪种方式能得到更满意的结果。 利用模型的特定功能：一些模型可能提供了特定的功能或参数调整选项，比如调整生成图像的分辨率、风格强度等，合理利用这些功能也可以帮助提高生成图像的质量。 通过上述方法，可以有效地提高使用文生图大模型时生成图像的质量。不过，由于不同的模型可能有不同的特点和偏好，实际操作中可能还需要根据具体模型的特性和反馈进行适当的调整。 可以参考如下示例： A futuristic ecofriendly skyscraper in central Tokyo. The building incorporates lush vertical gardens on every floor, with cascading plants and trees lining glass terraces. Solar panels and wind turbines are integrated into the structures design, reflecting a sustainable future. The Tokyo Tower is visible in the background, contrasting the modern ecoarchitecture with traditional city landmarks. An elegant snow leopard perched on a cliff in the Himalayan mountains, surrounded by swirling snow. The animals fur is intricately detailed with distinctive patterns and a thick winter coat. The scene captures the majesty and isolation of the leopards habitat, with mist and mountain peaks fading into the background. 根据现有图像，生成图像变体 有部分生图模型支持通过已有图像生成图像变体，这种情况下，仍然需要输入适当的prompt，才能达到预期的效果，具体prompt输入，可以参考上面内容。 2.体验地址 可以通过 图像生成 体验生图的功能，也可以通过 API文档 介绍，通过API进行调用。 重点参数介绍 imagesize：控制参数的图像分辨率，API请求时候，可以自定义多种分辨率。 numinferencesteps：控制图像生成的步长，有部分模型可以通过调整步长，获取生成效果更好的图像，其中模型blackforestlabsFLUX.1schnell、ProblackforestlabsFLUX.1schnell和stabilityaistablediffusion35largeturbo不支持调整步长，默认的步长是4。 promptenhancement：prompt增强开关，该开关打开后，会对输入的prompt进行一些增强，对于中文用户，想要快速通过中文生成图像，可以打开该开关，更好的适配中文。 batchsize：一次生成图像的个数，默认值是1，最大值可以设置为4 negativeprompt：这里可以输入图像中不想出现的某些元素，消除一些影响影响因素。 seed：如果想要每次都生成固定的图片，可以把seed设置为固定值。 3.生图计费介绍 平台的生图计费分为两种计费方式： 根据图像大小及图像步长进行计费，单价是 xM pxSteps，即每M像素每步长是x元。 比如想要生成一个宽1024高512、4步长的图像，选择单价是0.0032M pxSteps的stabilityaistablediffusion35largeturbo模型，那么生成一张图片的价格就是(1024x512)(1024x1024)x4x0.00320.0064元，其中2代表宽1024高512像素的大小是0.5M，生成一张图像的价格跟生成图像的像素大小和价格都有关系。 根据图片张数进行计费，单价是xImage，即每张图片的价格是x元。 比如想要生成一个宽1024高512像素，4步长的图像，选择单价是0.37Image的blackforestlabsFLUX.1pro模型，那么生成一张图片的价格就是0.37元，生成一张图像的价格，跟像素和步长都无关。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 4.支持模型列表 目前已支持的生图模型： 文生图系列： blackforestlabs系列： blackforestlabsFLUX.1dev blackforestlabsFLUX.1schnell ProblackforestlabsFLUX.1schnell blackforestlabsFLUX.1pro stabilityai系列： stabilityaistablediffusion35large stabilityaistablediffusion35largeturbo stabilityaistablediffusion3medium stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 deepseekai系列： deepseekaiJanusPro7B 默认出图为 384384 分辨率 图生图系列： stabilityai系列： stabilityaistablediffusionxlbase1.0 stabilityaistablediffusion21 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。    注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。 注意：选择的模型不一样，计费方式可能不同，请用户根据自身需求，选择相应计费方式的模型。  注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。 注意：支持的生图模型可能发生调整，请在模型广场筛选生图标签，了解支持的模型列表。 视频生成模型推理模型 视频生成模型推理模型 在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 在此页面1.生图模型简介2.体验地址3.生图计费介绍4.支持模型列表 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/use-docs-with-cursor": "SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用结合 Cursor 使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page开始使用结合 Cursor 使用 SiliconFlow home page SiliconFlow home page SiliconFlow home page 开始使用结合 Cursor 使用 开始使用结合 Cursor 使用 开始使用 结合 Cursor 使用 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050 快速上手视觉语言模型 SiliconCloud 文档站支持 llms.txt 协议，既可供用户直接查阅，也可无缝对接各类支持该协议的工具进行使用。 考虑到部分用户可能对 llms.txt 协议 不够熟悉，下面将简要介绍使用流程及相关概述。 1. 在 Cursor 中使用本文档 1.1 配置本文档 配置 Cursor 的 Docs 数据源，可以很方便的将本文档丢给 Cursor 使用。 1.2 在 cursor 中使用 2. 关于 llmx.txt 的相关介绍 2.1 协议背景 llms.txt 是一种新兴的 Web 标准，旨在帮助大型语言模型（LLMs）更有效地访问和理解网站内容。通过在网站根目录下创建 llms.txt 文件，网站所有者可以为 AI 系统提供清晰的导航和指引，从而提升信息检索的效率。 2.2 文件结构： llms.txt 文件采用 Markdown 格式，通常包含以下部分： 标题：网站名称或项目名称。 描述（可选）：对网站或项目的简要介绍。 详细信息（可选）：提供更多背景信息或链接到其他文档。 章节：列出网站的重要部分，每个部分包含链接和可选的详细说明。 示例如下（参考：https:docs.siliconflow.cnllms.txt 和 https:docs.siliconflow.cnllmsfull.txt 文件)  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 . 2.3 文件作用 2.3.1 llms.txt： 大规模人工智能友好导航：该文件提供了整个文档导航的简化视图，使 Cursor 或 ChatGPT 等 LLM 可以更轻松地索引您的内容。 将其视为人工智能的搜索引擎优化用户现在可以直接通过通用的 LLM 找到特定产品的信息。 2.3.2 llmsfull.txt： 文件会将所有文档文本编译成一个标记符文件，便于人工智能工具基于该文件将信息直接载入其上下文窗口。 可以将文档输入到 Cursor 等人工智能编码助手中，让它们根据您产品的具体细节提供上下文感知建议。 2.4 与现有标准的区别： 虽然 llms.txt 与 robots.txt 和 sitemap.xml 等现有标准在功能上有所重叠，但它们的目的和作用不同： robots.txt：用于指示搜索引擎爬虫哪些页面可以或不可以抓取，主要关注访问权限控制。 sitemap.xml：提供网站的结构地图，帮助搜索引擎了解网站的页面布局，主要用于索引目的。 llms.txt：为大型语言模型提供结构化的内容概述，帮助 AI 系统更好地理解和处理网站信息，提升与 AI 交互的效果。 3. 在其他工具中使用 其他平台如果支持llms.txt 协议，也可以直接使用。 比如在 ChatGPT 中使用： 4. 扩展阅读 The llms.txt file, https:llmstxt.org Docs, https:docs.cursor.comcontextsymbolsdocs LLMs.txt：AI时代的站点地图, https:juejin.cnpost7447083753187328050        SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 .  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 .  SiliconFlow  Docs  创建语音转文本请求(https:docs.siliconflow.cnapireferenceaudiocreateaudiotranscriptions): Creates an audio transcription.  创建文本转语音请求(https:docs.siliconflow.cnapireferenceaudiocreatespeech): 从输入文本生成音频。根据输入的文本生成音频。接口生成的数据为音频的二进制数据，需要使用者自行处理。参考：https:docs.siliconflow.cncapabilitiestexttospeech5  删除参考音频(https:docs.siliconflow.cnapireferenceaudiodeletevoice): 删除用户预置音色  上传参考音频(https:docs.siliconflow.cnapireferenceaudiouploadvoice): 上传用户预置音色，支持以 base64 编码或者文件形式上传，参考https:docs.siliconflow.cncapabilitiestexttospeech22)  参考音频列表获取(https:docs.siliconflow.cnapireferenceaudiovoicelist): 获取用户预置音色列表 .       快速上手视觉语言模型 快速上手视觉语言模型 在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 在此页面1. 在 Cursor 中使用本文档1.1 配置本文档1.2 在 cursor 中使用2. 关于 llmx.txt 的相关介绍 2.1 协议背景2.2 文件结构：2.3 文件作用2.3.1 llms.txt：2.3.2 llmsfull.txt：2.4 与现有标准的区别：3. 在其他工具中使用4. 扩展阅读 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/reasoning": "SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力推理模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力推理模型 SiliconFlow home page SiliconFlow home page SiliconFlow home page 平台能力推理模型 平台能力推理模型 平台能力 推理模型 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。 生图模型JSON 模式 概述 DeepSeekR1 是一系列由 deepseekai 开发的高级语言模型，旨在通过输出思维链内容（reasoningcontent）来提升最终回答的准确性。目前该接口和 deepseek 接口兼容，在使用该模型时，建议先升级 OpenAI SDK 以支持新参数。 支持模型列表： deepseekaiDeepSeekR1 ProdeepseekaiDeepSeekR1 deepseekaiDeepSeekR1DistillLlama70B deepseekaiDeepSeekR1DistillQwen32B deepseekaiDeepSeekR1DistillQwen14B deepseekaiDeepSeekR1DistillLlama8B deepseekaiDeepSeekR1DistillQwen7B deepseekaiDeepSeekR1DistillQwen1.5B ProdeepseekaiDeepSeekR1DistillLlama8B ProdeepseekaiDeepSeekR1DistillQwen7B ProdeepseekaiDeepSeekR1DistillQwen1.5B 安装与升级 在使用 DeepSeekR1 之前，请确保已安装最新版本的 OpenAI SDK。可以通过以下命令进行升级： pip3 install U openai API 参数 输入参数： maxtokens：回答的最大长度（包含思维链输出），其中上述模型列表中，deepseekaiDeepSeekR11和ProdeepseekaiDeepSeekR1 maxtokens 最大为8K，其他模型 maxtokens 最大为16k。 返回参数： reasoningcontent：思维链内容，与 content 同级。 content：最终回答内容 上下文拼接 在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 openai请求示例 流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) 非流式输出请求 from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) 注意事项 API 密钥：请确保使用正确的 API 密钥进行身份验证。 流式输出：流式输出适用于需要逐步接收响应的场景，而非流式输出则适用于一次性获取完整响应的场景。 常见问题 如何获取 API 密钥？ 请访问 SiliconFlow 注册并获取 API 密钥。 如何处理超长文本？ 可以通过调整 maxtokens 参数来控制输出的长度，但请注意最大长度为 16K。    pip3 install U openai pip3 install U openai pip3 install U openai     from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue ) from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) content   reasoningcontent messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue, maxtokens4096 ) for chunk in response: if chunk.choices0.delta.content: content  chunk.choices0.delta.content if chunk.choices0.delta.reasoningcontent: reasoningcontent  chunk.choices0.delta.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamTrue )  from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse ) from openai import OpenAI url  https:api.siliconflow.cnv1 apikey  your apikey client  OpenAI( baseurlurl, apikeyapikey ) messages   role: user, content: 奥运会的传奇名将有哪些？  response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse, maxtokens4096 ) content  response.choices0.message.content reasoningcontent  response.choices0.message.reasoningcontent messages.append(role: assistant, content: content) messages.append(role: user, content: 继续) response  client.chat.completions.create( modeldeepseekaiDeepSeekR1, messagesmessages, streamFalse )   生图模型JSON 模式 生图模型JSON 模式 在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 在此页面概述支持模型列表：安装与升级API 参数上下文拼接openai请求示例流式输出请求非流式输出请求注意事项常见问题 在此页面",
  "https://docs.siliconflow.cn/cn/usercases/use-siliconcloud-in-bob": "SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page场景示例在 Bob 翻译中使用用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page场景示例在 Bob 翻译中使用 SiliconFlow home page SiliconFlow home page SiliconFlow home page 场景示例在 Bob 翻译中使用 场景示例在 Bob 翻译中使用 场景示例 在 Bob 翻译中使用 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用 场景示例在 Bob 翻译中使用在 ChatHub 中使用在沉浸式翻译中使用在 Chatbox 中使用在 Dify 中使用在 Sider 中使用在 NextChat 中使用在 MindSearch 中使用在 Cherry Studio 中使用在 Obsidian Copilot 中使用在 DBGPT 中使用在 FastGPT 中使用在麦悠电台中使用在 302.AI 中使用在 Cline 中使用社区场景与应用 在 Bob 翻译中使用 在 Bob 翻译中使用 在 ChatHub 中使用 在 ChatHub 中使用 在沉浸式翻译中使用 在沉浸式翻译中使用 在 Chatbox 中使用 在 Chatbox 中使用 在 Dify 中使用 在 Dify 中使用 在 Sider 中使用 在 Sider 中使用 在 NextChat 中使用 在 NextChat 中使用 在 MindSearch 中使用 在 MindSearch 中使用 在 Cherry Studio 中使用 在 Cherry Studio 中使用 在 Obsidian Copilot 中使用 在 Obsidian Copilot 中使用 在 DBGPT 中使用 在 DBGPT 中使用 在 FastGPT 中使用 在 FastGPT 中使用 在麦悠电台中使用 在麦悠电台中使用 在 302.AI 中使用 在 302.AI 中使用 在 Cline 中使用 在 Cline 中使用 社区场景与应用 社区场景与应用 1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。 在 ChatHub 中使用 1. 关于 Bob Bob 是一款 macOS 平台的翻译和 OCR 软件，您可以在任何应用程序中使用 Bob 进行翻译和 OCR，即用即走，简单、快捷、高效！ 本文将介绍如何借助 SiliconCloud 提供的 API 服务在 Bob 中进行翻译。 2. 安装 Bob 前往 Mac App Store 安装 Bob。Mac App Store 安装 3. 在 Bob 中使用 SiliconCloud 3.1 默认配置 安装完 Bob 之后，在任意软件选中一段文本，然后按下  D 快捷键即可翻译，SiliconCloud 的免费模型会作为默认翻译服务进行翻译，如下图所示。 3.2 使用 SiliconCloud 的其他免费模型 默认使用的模型是 QwenQwen2.57BInstruct，可以使用鼠标右键点击翻译窗口右上角的服务图标前往翻译服务页面切换其他免费模型。 如下图所示，标注为免费的模型均可直接使用。 3.3 使用 SiliconCloud 的其他文本生成模型 如需使用没有标注为免费的模型，需要自行获取 SiliconCloud API Key。 打开 SiliconCloud 官网 并注册账号（如果注册过，直接登录即可）。 完成注册后，打开 API 密钥 ，创建新的 API Key，点击密钥进行复制，以备后续使用。 进入之前提到的 Bob翻译服务页面，将 API Key 填入硅基流动翻译服务的 API Key 设置项中，然后切换到需要使用的其他模型，点击保存即可使用。       在 ChatHub 中使用 在 ChatHub 中使用 在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 在此页面1. 关于 Bob2. 安装 Bob3. 在 Bob 中使用 SiliconCloud3.1 默认配置3.2 使用 SiliconCloud 的其他免费模型3.3 使用 SiliconCloud 的其他文本生成模型 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/guides/function-calling": "SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性Function Calling用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page功能特性Function Calling SiliconFlow home page SiliconFlow home page SiliconFlow home page 功能特性Function Calling 功能特性Function Calling 功能特性 Function Calling 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调 1. 使用场景 Function Calling 功能让模型能够调用外部工具，来增强自身能力。 该能力可以通过外部工具，通过大模型作为大脑调用外部工具（如搜索外部知识、查阅行程、或者某些特定领域工具），有效解决模型的幻觉、知识时效性等问题。 2. 使用方式 2.1 通过 REST API 添加 tools 请求参数 在请求体中添加 tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   比如完整的 payload 信息： payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  2.2 通过 OpenAI 库请求 该功能和openai兼容，在使用 OpenAI 的库时，对应的请求参数中添加tools对应的 tools 比如： response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) 3. 支持模型列表 目前支持的模型列表有： Deepseek 系列： deepseekaiDeepSeekV2.5 deepseekaiDeepSeekV3 书生系列： internlminternlm2520bchat internlminternlm257bchat Prointernlminternlm257bchat Qwen系列： QwenQwen2.572BInstruct QwenQwen2.532BInstruct QwenQwen2.514BInstruct QwenQwen2.57BInstruct ProQwenQwen2.57BInstruct GLM 系列： THUDMglm49bchat ProTHUDMglm49bchat 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 4. 使用示例 4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力 本代码输入 4 个函数，分别是数值的加、减、比较大小、字符串中重复字母计数四个函数 来演示通过function calling来解决大语言模型在tokens 预测不擅长的领域的执行问题。 from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) 模型将输出： strawberry中有3个r。 9.11 比 9.9 小。 4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 本代码输入 1 个函数，通过外部 API 来查询外部信息 import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) 模型将输出： The weather in Beijing today is sunny with a temperature of 21.4C.    tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表  payload   model: deepseekaiDeepSeekV2.5, messages:   role: user, content: 中国大模型行业2025年将会迎来哪些机遇和挑战  , tools:   type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:  comments: 此处是函数参数相关描述 ,  ,  comments: 其他函数相关说明   comments: 其他函数列表   response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, tools  type: function, function:  name: 对应到实际执行的函数名称, description: 此处是函数相关描述, parameters:   此处是函数参数相关描述 ,  ,   其他函数相关说明    chat.completions 其他参数 )  注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。 注意：支持的模型列表在不断调整中，请查阅本文档了解最新支持的模型列表。   from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def add(a: float, b: float): return a  b def mul(a: float, b: float): return a  b def compare(a: float, b: float): if a  b: return fa is greater than b elif a  b: return fb is greater than a else: return fa is equal to b def countletterinstring(a: str, b: str): string  a.lower() letter  b.lower() count  string.count(letter) return(fThe letter letter appears count times in the string.) tools    type: function, function:  name: add, description: Compute the sum of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: mul, description: Calculate the product of two numbers, parameters:  type: object, properties:  a:  type: int, description: A number, , b:  type: int, description: A number, , , required: a, b, ,  ,  type: function, function:  name: countletterinstring, description: Count letter number in a string, parameters:  type: object, properties:  a:  type: str, description: source string, , b:  type: str, description: letter, , , required: a, b, ,  ,  type: function, function:  name: compare, description: Compare two number, which one is bigger, parameters:  type: object, properties:  a:  type: float, description: A number, , b:  type: float, description: A number, , , required: a, b, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messages  messages, temperature0.01, topp0.95, streamFalse, toolstools) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools) return response.choices0.message.content prompts   用中文回答：strawberry中有多少个r?, 用中文回答：9.11和9.9，哪个小?  for prompt in prompts: print(functioncallplayground(prompt)) strawberry中有3个r。 9.11 比 9.9 小。 strawberry中有3个r。 9.11 比 9.9 小。 strawberry中有3个r。 9.11 比 9.9 小。  import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) import requests from openai import OpenAI client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) def getweather(city: str): apikey  您的WeatherAPI APIKEY baseurl  http:api.weatherapi.comv1current.json params   key: apikey, q: city, aqi: no  response  requests.get(baseurl, paramsparams) if response.statuscode  200: data  response.json() weather  datacurrentconditiontext temperature  datacurrenttempc return fThe weather in city is weather with a temperature of temperatureC. else: return fCould not retrieve weather information for city. tools    type: function, function:  name: getweather, description: Get the current weather for a given city., parameters:  type: object, properties:  city:  type: string, description: The name of the city to query weather for., , , required: city, ,    def functioncallplayground(prompt): messages  role: user, content: prompt response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) func1name  response.choices0.message.toolcalls0.function.name func1args  response.choices0.message.toolcalls0.function.arguments func1out  eval(ffunc1name(func1args)) messages.append(response.choices0.message) messages.append( role: tool, content: ffunc1out, toolcallid: response.choices0.message.toolcalls0.id ) response  client.chat.completions.create( modeldeepseekaiDeepSeekV2.5, messagesmessages, temperature0.01, topp0.95, streamFalse, toolstools ) return response.choices0.message.content prompt  how is the weather today in beijing? print(functioncallplayground(prompt)) The weather in Beijing today is sunny with a temperature of 21.4C. The weather in Beijing today is sunny with a temperature of 21.4C. The weather in Beijing today is sunny with a temperature of 21.4C. FIM 补全模型微调 FIM 补全模型微调 在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 在此页面1. 使用场景2. 使用方式2.1 通过 REST API 添加 tools 请求参数2.2 通过 OpenAI 库请求3. 支持模型列表4. 使用示例4.1. 示例 1：通过function calling 来扩展大语言模型的数值计算能力4.2. 示例 2：通过function calling 来扩展大语言模型对外部环境的理解 在此页面",
  "https://docs.siliconflow.cn/cn/userguide/capabilities/text-to-speech": "SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力文本转语音模型用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page平台能力文本转语音模型 SiliconFlow home page SiliconFlow home page SiliconFlow home page 平台能力文本转语音模型 平台能力文本转语音模型 平台能力 文本转语音模型 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型 1. 使用场景 文本转语音模型（TTS）是一种将文本信息转换为语音输出的 AI 模型。该模型将输入文本内容生成自然流畅、富有表现力的语音，适用于多种应用场景： 为博客文章提供音频朗读 生成多语言语音内容 支持实时流媒体音频输出 2. API 使用指南 端点：audiospeech，具体使用可参考api文档 主要请求参数： model：用于语音合成的模型，支持的模型列表。 input：待转换为音频的文本内容。 voice：参考音色，支持系统预置音色、用户预置音色、用户动态音色。 详细参数请参考：创建文本转语音请求。 speed：可以控制音频速度，float类型，默认值是1.0，可选范围是0.25,4.0 gain：音频增益，单位dB，可以控制音频声音大小，float类型，默认值是0.0，可选范围是10,10 responseformat：控制输出格式，支持 mp3、opus、wav 和 pcm 格式。在选择不同的输出格式时，输出的采样率也会有所不同。 samplerate：可以控制输出采样率，对于不同的视频输出类型，默认值和可取值范围均不同，具体如下： opus: 目前只支持48000hz wav, pcm: 支持 (8000, 16000, 24000, 32000, 44100), 默认44100 mp3: 支持(32000, 44100), 默认44100 2.1 系统预置音色： 目前系统预置了如下 8 种音色： 男生音色： 沉稳男声: alex 低沉男声: benjamin 磁性男声: charles 欢快男声: david 女生音色： 沉稳女声: anna 激情女声: bella 温柔女声: claire 欢快女声: diana 在线试听上述音频。 在请求中使用系统预置音色。 在使用对应的系统预置音色时，需要在前面加上模型名称，比如： FunAudioLLMCosyVoice20.5B:alex 表示 FunAudioLLMCosyVoice20.5B 模型下的 alex 音色。 fishaudiofishspeech1.5:anna 表示 fishaudiofishspeech1.5 模型下的 anna 音色。 RVCBossGPTSoVITS:david 表示 RVCBossGPTSoVITS 模型下的 david 音色。 2.2 用户预置音色： 注意：使用用户预置音色，需要进行实名认证。 为保证生成语音效果，建议用户上传音色为：时间810s左右，发音吐字清晰，没有杂音背景音。 2.2.1 通过 base64 编码格式上传用户预置音色 import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.2.2 通过文件上传用户预置音色 import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.3 获取用户动态音色列表 import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) 上述接口返回的 uri 字段，即为自定义音色的 ID，用户可以将其作为后续的 voice 参数中，进行请求。 uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd 在请求中使用用户预置音色。 2.4 使用用户动态音色 注意：使用用户预置音色，需要进行实名认证。 在请求中使用用户动态音色。 2.5 删除用户动态音色 import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) 上述接口请求参数中的 uri 字段，即为自定义音色的 ID。 3. 支持模型列表 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 3.1 fishaudiofishspeech 系列模型 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 fishspeech1.5 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语、俄语、荷兰语、意大利语、波兰语、葡萄牙语 fishspeech1.4 支持语言：中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语 3.2 RVCBossGPTSoVITS 系列模型 零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。 跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。 3.3 FunAudioLLMCosyVoice20.5B 系列模型 跨语言语音合成：实现不同语言之间的语音合成，中文、英文、日语、韩语、中国方言（粤语，四川话，上海话，郑州话，长沙话，天津话） 情感控制：支持生成具有多种情感表达的语音，包括快乐、兴奋、悲伤、愤怒等。 细粒度控制：通过富文本或自然语言，对生成语音的情感和韵律进行细粒度控制。 4. 参考音频的最佳实践 提供参考音频的高质量样本可以提升语音克隆效果。 4.1 音频质量指南 仅限单一说话人 稳定的音量、音调和情绪 简短的停顿（建议 0.5 秒） 理想情况：无背景噪音、专业录音质量、无房间回声 4.2 文件格式 支持格式：mp3, wav, pcm, opus 推荐使用 192kbps 以上的 mp3 以避免质量损失 未压缩格式（例如 WAV）提供的额外优势有限 5. 使用示例 5.1 使用系统预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.2 使用用户预置音色 from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) 5.3 使用用户动态音色 from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath)     注意：使用用户预置音色，需要进行实名认证。 注意：使用用户预置音色，需要进行实名认证。  import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) import requests import json url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, audio: data:audiompegbase64,SUQzBAAAAAAAIlRTU0UAAAAOAAADTGF2ZjYxLjcuMTAwAAAAAAAAAAAAAAD40DAAAAAAAAAAAAASW5mbwAAAA8AAAAWAAAJywAfHx8fKioqKio1NTU1Pz8Pz9KSkpKVVVVVVVfX19fampqamp1dXV1f39f3KioqKlZWVlZWfn5fn6qqqqq1tbW1tbv7KysrKytXV1dXf39f3rq6ur19fX19f, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, datajson.dumps(data)) print(response.statuscode) print(response.json()) uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd  import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) import requests url  https:api.siliconflow.cnv1uploadsaudiovoice headers   Authorization: Bearer yourapikey  files   file: open(UserssensebDownloadsfishaudioAlex.mp3, rb)  data   model: FunAudioLLMCosyVoice20.5B, customName: yourvoicename, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始  response  requests.post(url, headersheaders, filesfiles, datadata) print(response.statuscode) print(response.json()) uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd  import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) import requests url  https:api.siliconflow.cnv1audiovoicelist headers   Authorization: Bearer yourapikey  response  requests.get(url, headersheaders) print(response.statuscode) print(response.json) uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd uri: speech:yourvoicename:cm04pf7az00061413w7kz5qxs:mjtkgbyuunvtybnsvbxd  注意：使用用户预置音色，需要进行实名认证。 注意：使用用户预置音色，需要进行实名认证。  import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text) import requests url  https:api.siliconflow.cnv1audiovoicedeletions headers   Authorization: Bearer yourapikey, ContentType: applicationjson  data   uri: speech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd  response  requests.post(url, headersheaders, datadata) print(response.statuscode) print(response.text)  注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 注意：支持的 TTS 模型可能发生调整，请在模型广场筛选语音标签 获得当前支持的模型列表。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。 计费方式：按照输入文本长度对应的 UTF8 字节 数进行计费，在线字节计数器演示。  注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。 注意：当前的 fishaudiofishspeech 系列模型仅支持使用充值余额进行支付。在使用前，请确保账户充值余额充足。        from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voiceFunAudioLLMCosyVoice20.5B:alex, input你能用高兴的情感说吗？endofprompt今天真是太开心了，马上要放假了！Im so happy, Spring Festival is coming!, responseformatmp3 ) as response: response.streamtofile(speechfilepath)  from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voicespeech:yourvoicename:cm02pf7az00061413w7kz5qxs:mttkgbyuunvtybnsvbxd, input 请问你能模仿粤语的口音吗？ endofprompt 多保重，早休息。, responseformatmp3 ) as response: response.streamtofile(speechfilepath)  from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) from pathlib import Path from openai import OpenAI client  OpenAI() speechfilepath  Path(file).parent  siliconcloudgeneratedspeech.mp3 client  OpenAI( apikey您的 APIKEY, baseurlhttps:api.siliconflow.cnv1 ) with client.audio.speech.withstreamingresponse.create( modelFunAudioLLMCosyVoice20.5B, voice, input laughter有时候，看着小孩子们的天真行为laughter，我们总会会心一笑。, responseformatmp3, extrabodyreferences:  audio: https:sfmaasuatprod.osscnshanghai.aliyuncs.comvoicetemplatefishaudioAlex.mp3, text: 在一无所知中, 梦里的一天结束了，一个新的轮回便会开始,   ) as response: response.streamtofile(speechfilepath) 视觉语言模型视频生成模型 视觉语言模型视频生成模型 在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 在此页面1. 使用场景2. API 使用指南2.1 系统预置音色：2.2 用户预置音色：2.2.1 通过 base64 编码格式上传用户预置音色2.2.2 通过文件上传用户预置音色2.3 获取用户动态音色列表2.4 使用用户动态音色2.5 删除用户动态音色3. 支持模型列表3.1 fishaudiofishspeech 系列模型3.2 RVCBossGPTSoVITS 系列模型3.3 FunAudioLLMCosyVoice20.5B 系列模型4. 参考音频的最佳实践4.1 音频质量指南4.2 文件格式5. 使用示例5.1 使用系统预置音色5.2 使用用户预置音色5.3 使用用户动态音色 在此页面",
  "https://docs.siliconflow.cn/cn/api-reference/chat-completions/chat-completions": "SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page文本系列创建文本对话请求用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home page文本系列创建文本对话请求 SiliconFlow home page SiliconFlow home page SiliconFlow home page 文本系列创建文本对话请求 文本系列创建文本对话请求 文本系列 创建文本对话请求 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求图像系列POST创建图片生成请求语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频视频系列POST创建视频生成请求POST获取视频生成链接请求平台系列GET获取用户模型列表GET获取用户账户信息 文本系列POST创建文本对话请求POST创建嵌入请求POST创建重排序请求 创建文本对话请求 创建文本对话请求 创建嵌入请求 创建嵌入请求 创建重排序请求 创建重排序请求 图像系列POST创建图片生成请求 创建图片生成请求 创建图片生成请求 语音系列POST上传参考音频POST创建文本转语音请求POST创建语音转文本请求GET参考音频列表获取POST删除参考音频 上传参考音频 上传参考音频 创建文本转语音请求 创建文本转语音请求 创建语音转文本请求 创建语音转文本请求 参考音频列表获取 参考音频列表获取 删除参考音频 删除参考音频 视频系列POST创建视频生成请求POST获取视频生成链接请求 创建视频生成请求 创建视频生成请求 获取视频生成链接请求 获取视频生成链接请求 平台系列GET获取用户模型列表GET获取用户账户信息 获取用户模型列表 获取用户模型列表 获取用户账户信息 获取用户账户信息 POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 POSTchatcompletionsAuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger创建嵌入请求 POSTchatcompletions POSTchatcompletions POSTchatcompletions POSTchatcompletions POSTchatcompletions POST chatcompletions chatcompletions  chat  completions AuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api keyBodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger AuthorizationsAuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api key Authorizations AuthorizationstringheaderrequiredUse the following format for authentication: Bearer your api key Authorizationstringheaderrequired Authorizationstringheaderrequired Authorizationstringheaderrequired  Authorization stringheaderrequired string string header header Use the following format for authentication: Bearer your api key Use the following format for authentication: Bearer your api key BodyapplicationjsonmessagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. Bodyapplicationjson applicationjson applicationjson messagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. messagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192nintegerdefault:1Number of generations to returnresponseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format.stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONEtemperaturenumberdefault:0.7Determines the degree of randomness in the response.toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function topknumberdefault:50toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. messagesobjectrequiredA list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system messagesobjectrequired messagesobjectrequired messagesobjectrequired  messages objectrequired object object A list of messages comprising the conversation so far.messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system A list of messages comprising the conversation so far. messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message.messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？requiredThe contents of the message. messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？required messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？required messages.contentstringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？required  messages.content stringdefault:中国大模型行业2025年将会迎来哪些机遇和挑战？required string string default:中国大模型行业2025年将会迎来哪些机遇和挑战？ 中国大模型行业2025年将会迎来哪些机遇和挑战？ The contents of the message. The contents of the message. messages.roleenumstringdefault:userrequiredThe role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system messages.roleenumstringdefault:userrequired messages.roleenumstringdefault:userrequired messages.roleenumstringdefault:userrequired  messages.role enumstringdefault:userrequired enumstring enumstring default:user user The role of the messages author. Choice between: system, user, or assistant.Available options: user, assistant, system The role of the messages author. Choice between: system, user, or assistant. Available options: user, assistant, system user, assistant, system modelenumstringdefault:deepseekaiDeepSeekV3required对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit modelenumstringdefault:deepseekaiDeepSeekV3required modelenumstringdefault:deepseekaiDeepSeekV3required modelenumstringdefault:deepseekaiDeepSeekV3required  model enumstringdefault:deepseekaiDeepSeekV3required enumstring enumstring default:deepseekaiDeepSeekV3 deepseekaiDeepSeekV3 对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit 对应的模型名称。为更好的提升服务质量，我们将不定期对本服务提供的模型做相关变更，包括但不限于模型上下线，模型服务能力调整，我们会在可行的情况下以公告、消息推送等适当的方式进行通知。 Available options: deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit deepseekaiDeepSeekR1, ProdeepseekaiDeepSeekR1, deepseekaiDeepSeekV3, ProdeepseekaiDeepSeekV3, deepseekaiDeepSeekR1DistillLlama70B, deepseekaiDeepSeekR1DistillQwen32B, deepseekaiDeepSeekR1DistillQwen14B, deepseekaiDeepSeekR1DistillLlama8B, deepseekaiDeepSeekR1DistillQwen7B, deepseekaiDeepSeekR1DistillQwen1.5B, ProdeepseekaiDeepSeekR1DistillLlama8B, ProdeepseekaiDeepSeekR1DistillQwen7B, ProdeepseekaiDeepSeekR1DistillQwen1.5B, metallamaLlama3.370BInstruct, AIDCAIMarcoo1, deepseekaiDeepSeekV2.5, QwenQwen2.572BInstruct128K, QwenQwen2.572BInstruct, QwenQwen2.532BInstruct, QwenQwen2.514BInstruct, QwenQwen2.57BInstruct, QwenQwen2.5Coder32BInstruct, QwenQwen2.5Coder7BInstruct, QwenQwen27BInstruct, QwenQwen21.5BInstruct, QwenQwQ32BPreview, TeleAITeleChat2, 01aiYi1.534BChat16K, 01aiYi1.59BChat16K, 01aiYi1.56BChat, THUDMglm49bchat, VendorAQwenQwen2.572BInstruct, internlminternlm257bchat, internlminternlm2520bchat, nvidiaLlama3.1Nemotron70BInstruct, metallamaMetaLlama3.1405BInstruct, metallamaMetaLlama3.170BInstruct, metallamaMetaLlama3.18BInstruct, googlegemma227bit, googlegemma29bit, ProQwenQwen2.57BInstruct, ProQwenQwen27BInstruct, ProQwenQwen21.5BInstruct, ProTHUDMchatglm36b, ProTHUDMglm49bchat, PrometallamaMetaLlama3.18BInstruct, Progooglegemma29bit frequencypenaltynumberdefault:0.5 frequencypenaltynumberdefault:0.5 frequencypenaltynumberdefault:0.5 frequencypenaltynumberdefault:0.5  frequencypenalty numberdefault:0.5 number number default:0.5 0.5 maxtokensintegerdefault:512The maximum number of tokens to generate.Required range: 1  x  8192 maxtokensintegerdefault:512 maxtokensintegerdefault:512 maxtokensintegerdefault:512  maxtokens integerdefault:512 integer integer default:512 512 The maximum number of tokens to generate.Required range: 1  x  8192 The maximum number of tokens to generate. Required range: 1  x  8192 nintegerdefault:1Number of generations to return nintegerdefault:1 nintegerdefault:1 nintegerdefault:1  n integerdefault:1 integer integer default:1 1 Number of generations to return Number of generations to return responseformatobjectAn object specifying the format that the model must output.responseformat.typestringThe type of the response format. responseformatobject responseformatobject responseformatobject  responseformat object object object An object specifying the format that the model must output.responseformat.typestringThe type of the response format. An object specifying the format that the model must output. responseformat.typestringThe type of the response format. responseformat.typestringThe type of the response format. responseformat.typestringThe type of the response format. responseformat.typestringThe type of the response format. responseformat.typestring responseformat.typestring responseformat.typestring  responseformat.type string string string The type of the response format. The type of the response format. stopOption 1  string  nullOption 2  string  nullOption 3  string  nullUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. stopOption 1  string  nullOption 2  string  nullOption 3  string  null stopOption 1  string  nullOption 2  string  nullOption 3  string  null stopOption 1  string  nullOption 2  string  nullOption 3  string  null  stop Option 1  string  nullOption 2  string  nullOption 3  string  null Option 1  string  nullOption 2  string  nullOption 3  string  null Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. streambooleandefault:falseIf set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONE streambooleandefault:false streambooleandefault:false streambooleandefault:false  stream booleandefault:false boolean boolean default:false false If set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONE If set, tokens are returned as ServerSent Events as they are made available. Stream terminates with data: DONE temperaturenumberdefault:0.7Determines the degree of randomness in the response. temperaturenumberdefault:0.7 temperaturenumberdefault:0.7 temperaturenumberdefault:0.7  temperature numberdefault:0.7 number number default:0.7 0.7 Determines the degree of randomness in the response. Determines the degree of randomness in the response. toolsobjectA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function toolsobject toolsobject toolsobject  tools object object object A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported. tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide.tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function tools.functionobjectrequiredtools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.functionobjectrequired tools.functionobjectrequired tools.functionobjectrequired  tools.function objectrequired object object tools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64.tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function.tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list.tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.function.namestringrequiredThe name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64. tools.function.namestringrequired tools.function.namestringrequired tools.function.namestringrequired  tools.function.name stringrequired string string The name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64. The name of the function to be called. Must be az, AZ, 09, or contain underscores and dashes, with a maximum length of 64. tools.function.descriptionstringA description of what the function does, used by the model to choose when and how to call the function. tools.function.descriptionstring tools.function.descriptionstring tools.function.descriptionstring  tools.function.description string string string A description of what the function does, used by the model to choose when and how to call the function. A description of what the function does, used by the model to choose when and how to call the function. tools.function.parametersobjectThe parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list. tools.function.parametersobject tools.function.parametersobject tools.function.parametersobject  tools.function.parameters object object object The parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list. The parameters the functions accepts, described as a JSON Schema object. See the guide for examples, and the JSON Schema reference for documentation about the format. Omitting parameters defines a function with an empty parameter list. tools.function.strictboolean  nulldefault:falseWhether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.function.strictboolean  nulldefault:false tools.function.strictboolean  nulldefault:false tools.function.strictboolean  nulldefault:false  tools.function.strict boolean  nulldefault:false boolean  null boolean  null default:false false Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the function calling guide. tools.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function tools.typeenumstringrequired tools.typeenumstringrequired tools.typeenumstringrequired  tools.type enumstringrequired enumstring enumstring The type of the tool. Currently, only function is supported.Available options: function The type of the tool. Currently, only function is supported. Available options: function function topknumberdefault:50 topknumberdefault:50 topknumberdefault:50 topknumberdefault:50  topk numberdefault:50 number number default:50 50 toppnumberdefault:0.7The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. toppnumberdefault:0.7 toppnumberdefault:0.7 toppnumberdefault:0.7  topp numberdefault:0.7 number number default:0.7 0.7 The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. The topp (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. Response200  applicationjsonchoicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestringcreatedintegeridstringmodelstringobjectenumstringAvailable options: chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger Response200  applicationjson 200  applicationjson 200  applicationjson choicesobjectchoices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choicesobject choicesobject choicesobject  choices object object object choices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.finishreasonenumstringAvailable options: stop, eos, length, toolcalls choices.finishreasonenumstring choices.finishreasonenumstring choices.finishreasonenumstring  choices.finishreason enumstring enumstring enumstring Available options: stop, eos, length, toolcalls Available options: stop, eos, length, toolcalls stop, eos, length, toolcalls choices.messageobjectchoices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.messageobject choices.messageobject choices.messageobject  choices.message object object object choices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.message.contentstringchoices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。choices.message.rolestring choices.message.contentstring choices.message.contentstring choices.message.contentstring choices.message.contentstring  choices.message.content string string string choices.message.reasoningcontentstring仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 choices.message.reasoningcontentstring choices.message.reasoningcontentstring choices.message.reasoningcontentstring  choices.message.reasoningcontent string string string 仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 仅d推理模型支持该返回，该部分返回思维链内容，与content同级。在每一轮对话过程中，模型会输出思维链内容（reasoningcontent）和最终回答（content）。在下一轮对话中，之前轮输出的思维链内容不会被拼接到上下文中。 choices.message.rolestring choices.message.rolestring choices.message.rolestring choices.message.rolestring  choices.message.role string string string createdinteger createdinteger createdinteger createdinteger  created integer integer integer idstring idstring idstring idstring  id string string string modelstring modelstring modelstring modelstring  model string string string objectenumstringAvailable options: chat.completion objectenumstring objectenumstring objectenumstring  object enumstring enumstring enumstring Available options: chat.completion Available options: chat.completion chat.completion toolcallsobjectThe tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function toolcallsobject toolcallsobject toolcallsobject  toolcalls object object object The tool calls generated by the model, such as function calls.toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function The tool calls generated by the model, such as function calls. toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call.toolcalls.idstringrequiredThe ID of the tool call.toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function toolcalls.functionobjectrequiredThe function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call. toolcalls.functionobjectrequired toolcalls.functionobjectrequired toolcalls.functionobjectrequired  toolcalls.function objectrequired object object The function that the model called.toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call. The function that the model called. toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call. toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call. toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.toolcalls.function.namestringrequiredThe name of the function to call. toolcalls.function.argumentsstringrequiredThe arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. toolcalls.function.argumentsstringrequired toolcalls.function.argumentsstringrequired toolcalls.function.argumentsstringrequired  toolcalls.function.arguments stringrequired string string The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. toolcalls.function.namestringrequiredThe name of the function to call. toolcalls.function.namestringrequired toolcalls.function.namestringrequired toolcalls.function.namestringrequired  toolcalls.function.name stringrequired string string The name of the function to call. The name of the function to call. toolcalls.idstringrequiredThe ID of the tool call. toolcalls.idstringrequired toolcalls.idstringrequired toolcalls.idstringrequired  toolcalls.id stringrequired string string The ID of the tool call. The ID of the tool call. toolcalls.typeenumstringrequiredThe type of the tool. Currently, only function is supported.Available options: function toolcalls.typeenumstringrequired toolcalls.typeenumstringrequired toolcalls.typeenumstringrequired  toolcalls.type enumstringrequired enumstring enumstring The type of the tool. Currently, only function is supported.Available options: function The type of the tool. Currently, only function is supported. Available options: function function usageobjectusage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger usageobject usageobject usageobject  usage object object object usage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger usage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger usage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger usage.completiontokensintegerusage.prompttokensintegerusage.totaltokensinteger usage.completiontokensinteger usage.completiontokensinteger usage.completiontokensinteger usage.completiontokensinteger  usage.completiontokens integer integer integer usage.prompttokensinteger usage.prompttokensinteger usage.prompttokensinteger usage.prompttokensinteger  usage.prompttokens integer integer integer usage.totaltokensinteger usage.totaltokensinteger usage.totaltokensinteger usage.totaltokensinteger  usage.totaltokens integer integer integer 创建嵌入请求 创建嵌入请求",
  "https://docs.siliconflow.cn/cn/userguide/rate-limits/rate-limit-and-upgradation": "SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home pageRate LimitsRate Limits用户指南场景示例API手册常见问题更新公告条款与协议 SiliconFlow home pageRate LimitsRate Limits SiliconFlow home page SiliconFlow home page SiliconFlow home page Rate LimitsRate Limits Rate LimitsRate Limits Rate Limits Rate Limits 用户指南场景示例API手册常见问题更新公告条款与协议 用户指南场景示例API手册常见问题更新公告条款与协议 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调Rate LimitsRate Limits硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 开始使用产品简介快速上手结合 Cursor 使用 产品简介 产品简介 快速上手 快速上手 结合 Cursor 使用 结合 Cursor 使用 平台能力视觉语言模型文本转语音模型视频生成模型生图模型推理模型 视觉语言模型 视觉语言模型 文本转语音模型 文本转语音模型 视频生成模型 视频生成模型 生图模型 生图模型 推理模型 推理模型 功能特性JSON 模式前缀续写FIM 补全Function Calling模型微调 JSON 模式 JSON 模式 前缀续写 前缀续写 FIM 补全 FIM 补全 Function Calling Function Calling 模型微调 模型微调 Rate LimitsRate Limits Rate Limits Rate Limits 硅基流动产品集SiliconCloud 平台BizyAir 文档OneDiff 多模态推理加速引擎SiliconLLM 大语言推理加速引擎 SiliconCloud 平台 SiliconCloud 平台 BizyAir 文档 BizyAir 文档 OneDiff 多模态推理加速引擎 OneDiff 多模态推理加速引擎 SiliconLLM 大语言推理加速引擎 SiliconLLM 大语言推理加速引擎 1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。 模型微调SiliconCloud 平台 1. Rate Limits 概述 1.1 什么是 Rate Limits Rate Limits 是指用户 API 在指定时间内访问 SiliconCloud 平台服务频次规则。 1.2 为什么做 Rate Limits Rate Limits 是 API 的常见做法，其实施原因如下： 保障资源的公平性及合理利用：确保资源公平使用。 防止某些用户过多请求，影响其他用户的正常使用体验。 防止请求过载：提高服务可靠性。帮助管理平台总体负载，避免因请求激增而导致服务器出现性能问题。 安全防护：防止恶意性攻击，导致平台过载甚至服务中断。 1.3 Rate Limits 指标 目前Rate Limit以六种指标衡量： RPM（ requests per minute，一分钟最多发起的请求数） RPD (Requests Per Day，每天允许的最大请求数) TPM（ tokens per minute，一分钟最多允许的 token 数） TPD（ tokens per Day，每天最多允许的 token 数） IPM（ images per minute，一分钟最多生成的图片数） IPD（ images per day，一天最多生成的图片数） 1.4 不同模型的 Rate Limits 指标 模型名称Rate Limit指标当前指标语言模型(Chat)RPM、 TPMRPM100010000 TPM500005000000向量模型(Embedding)RPM、 TPMRPM:200010000 TPM:50000010000000重排序模型(Reranker)RPM、 TPMRPM:2000 TPM:500000图像生成模型(Image)IPM、IPDIPM:2 IPD:400多模态模型 (Multimodal Models) Rate Limits 可能会因在任一选项（RPM、RPD、TPM、TPD、IPM、IPD）中达峰而触发，取决于哪个先发生。 例如，在 RPM 限制为20，TPM 限制为 200K 时，一分钟内，账户向 ChatCompletions 发送了 20 个请求，每个请求有 100个Token ，限制即触发，即使账户在这些 20 个请求中没有发满 200K 个 Token。 1.5 Rate Limits 主体 Rate Limit是在用户账户级别定义的，而不是密钥（API key）维度。 每个模型单独设置 Rate Limits，一个模型请求超出 Rate Limits 不影响其他模型正常使用。 2. Rate Limits 规则 当前免费模型 Rate Limits 指标是固定值，收费模型根据账户用量级别有不同的 Rate Limits 指标。 同一用量级别下，模型类别不同、模型参数量不同，Rate Limits 峰值不同。 2.1 免费模型Rate Limits 实名认证后使用全部的免费模型。 免费模型调用免费，账户的费用账单中看到此类模型的费用为调用消耗是 0。 免费模型的 Rate Limits 固定。对于部分模型，平台同时提供免费版和收费版。免费版按照原名称命名收费版会在名称前加上Pro以示区分。例如，Qwen2.57BInstruct 的免费版命名为QwenQwen2.57BInstruct，收费版则命名为ProQwenQwen2.57BInstruct。 2.2 收费模型 Rate Limits 按照用量付费。API 调用消耗计入账户费用账单。 根据账户用量级别进行分层 Rate Limits 。 Rate Limits 峰值随着用量级别提升而增大。 同一用量级别下，模型类别不同、模型参数量大小不同， Rate Limits 峰值不同。 2.3 用户用量级别与 Rate Limits 平台依据账户每月消费金额将其划分为不同的用量级别，每个级别有各自的 Rate Limits 标准。月消费达到更高级别标准时，自动升级至相应用量级别。升级立即生效，并提供更宽松的 Rate Limits。 月消费金额：包含充值金额消费和赠送金额在内的账户每个月的总消费金额。 级别设置：比较上个自然月和当月 1 号到今日的消费金额，取最高值换算成对应的用量级别。新用户注册后初始用量级别为L0。 用量级别资质（单位：人民币元）L0上月或当月消费金额最高值  50L150  上月或当月消费金额最高值  200L2200  上月或当月消费金额最高值  2000L32000  上月或当月消费金额最高值  5000L45000  上月或当月消费金额最高值  10000L510000  上月或当月消费金额最高值 2.4 具体模型的 Rate Limits 平台目前提供文本生成、图像生成、向量化、重排序和语音五大类，具体模型的 Rate Limits 指标在模型广场中查看。 2.5 部分模型是否实名的 Rate Limits 模型DeepSeekR1 和 DeepSeekV3 ，会根据是否实名对Rate Limits进行区分： 未实名用户用户：每天仅能访问 100次。如果当天访问次数超过 100次，将收到 429 错误，并提示 Details: RPD limit reached. Could only send 100 requests per day without real name verification，可以通过实名解锁更高的 Rate Limit。 实名用户：拥有更高的 Rate Limit，具体值参考模型广场 如果访问次数超过这些限制，也会收到 429 错误。 3. 超出 Rate Limits 处理 3.1 超出 Rate Limits 报错信息 如果超出 Rate Limits 调用限制，用户的 API 请求将会因为超过 Rate Limits 而失败。用户需要等待一段时间待满足 Rate Limits 条件后方能再次调用。对应的 HTTP 错误信息为： HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn 3.2 超出 Rate Limits 处理方式 在已有的Rate Limits下，可以参考 超出 Rate Limits 处理 进行错误回避。 也可以通过提升用量级别来提升模型 Rate Limits 峰值，业务目标。 4. 如何提升模型 Rate Limits 指标 4.1 提升 Rate Limits 的方式 根据用量自动升级：您可以通过提高用量来增加月消费金额，满足下一级别资质时，会自动升级。 购买等级包快速提升：如果您需要快速达到更高用量级别、提高 Rate Limits 峰值，可以通过购买等级包来提升用量级别。 4.2 等级包购买细则 在线购买：请前往平台在线购买 等级包 有效时间：等级包购买后立即生效，适用于当月（N）和下一个自然月（N1）。自下下个自然月（N2）起，将根据上一个月（N1）的消费金额重新计算账户的最新用量级别。 支付方式：等级包仅支持使用平台充值余额支付，不支持使用平台赠送余额支付。 发票开具：关于等级包的发票开具，参考开具发票部分。 专属实例：等级包不适用于专属实例需求，若有相关需求，请联系您的专属客户经理。 4.3 其他情况 联系我们：不属于上述情况的场景，请联系我们。               HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn HTTP1.1 429 Too Many Requests Content Type: applicationjson Request was rejected due to rate limiting. If you want more, please contact contactsiliconflow.cn      模型微调SiliconCloud 平台 模型微调SiliconCloud 平台 在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 在此页面1. Rate Limits 概述1.1 什么是 Rate Limits1.2 为什么做 Rate Limits1.3 Rate Limits 指标1.4 不同模型的 Rate Limits 指标1.5 Rate Limits 主体2. Rate Limits 规则2.1 免费模型Rate Limits2.2 收费模型 Rate Limits2.3 用户用量级别与 Rate Limits2.4 具体模型的 Rate Limits2.5 部分模型是否实名的 Rate Limits3. 超出 Rate Limits 处理3.1 超出 Rate Limits 报错信息3.2 超出 Rate Limits 处理方式4. 如何提升模型 Rate Limits 指标4.1 提升 Rate Limits 的方式4.2 等级包购买细则4.3 其他情况 在此页面"
}